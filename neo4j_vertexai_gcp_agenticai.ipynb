{
  "cells": [
    {
      "cell_type": "code",
      "id": "LdEFjeS67VHZPbPO8bwYU5qY",
      "metadata": {
        "tags": [],
        "id": "LdEFjeS67VHZPbPO8bwYU5qY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838063130,
          "user_tz": -330,
          "elapsed": 5494,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "18f88f7f-9bae-49c2-86c3-7271eca66114"
      },
      "source": [
        "!pip install -U langchain-google-vertexai langchain langchain-community"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-vertexai in /usr/local/lib/python3.10/dist-packages (2.0.19)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.21)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.85.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (1.87.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (2.19.0)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (0.4.0)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.49 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (0.3.51)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.9 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (2.10.4)\n",
            "Requirement already satisfied: validators<0.35.0,>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (0.34.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (4.25.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (24.2)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (4.12.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (1.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.49->langchain-google-vertexai) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=2.9->langchain-google-vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=2.9->langchain-google-vertexai) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.49->langchain-google-vertexai) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.85.0->langchain-google-vertexai) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://pypi.org/project/langchain-google-vertexai/\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "llm = ChatVertexAI(model_name=\"gemini-2.0-flash-001\")\n",
        "llm.invoke(\"Sing a ballad of LangChain.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibYdkWpUQtd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838086138,
          "user_tz": -330,
          "elapsed": 11372,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b3e69529-667b-4caf-ab32-85ca2782519f"
      },
      "id": "oibYdkWpUQtd",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='(Verse 1)\\nThe code was dark, the data deep, a maze of logic\\'s keep,\\nWhere AI models strove to learn, and promises they\\'d reap.\\nBut tasks complex, a tangled thread, a challenge hard to face,\\nUntil a hero rose and said, \"I\\'ll bring it into place!\"\\n\\n(Chorus)\\nOh, LangChain, LangChain, you guide us through the night,\\nA framework strong, a beacon bright, you help us do what\\'s right.\\nFrom LLMs vast to knowledge banks of yore,\\nYou weave the threads and open up the door!\\n\\n(Verse 2)\\nWith chains of prompts and agents bold, and memories keen and true,\\nThe power of the language told, in ways we never knew.\\nFrom chatbots smart to question deep, you answer with a grace,\\nAnd solve the problems while we sleep, and leave no time or space.\\n\\n(Chorus)\\nOh, LangChain, LangChain, you guide us through the night,\\nA framework strong, a beacon bright, you help us do what\\'s right.\\nFrom LLMs vast to knowledge banks of yore,\\nYou weave the threads and open up the door!\\n\\n(Verse 3)\\nThe pipelines flow, the agents strive, with tools and APIs,\\nTo conquer tasks and keep alive, the promise in our eyes.\\nFrom document to data store, you connect the dots with ease,\\nAnd unlock insights we adore, and put our minds at peace.\\n\\n(Chorus)\\nOh, LangChain, LangChain, you guide us through the night,\\nA framework strong, a beacon bright, you help us do what\\'s right.\\nFrom LLMs vast to knowledge banks of yore,\\nYou weave the threads and open up the door!\\n\\n(Verse 4)\\nSo raise a glass to open source, and all who contribute,\\nTo LangChain\\'s rise, a powerful force, a future absolute.\\nMay your chains be strong, your agents swift, your knowledge ever grow,\\nAnd with your help, we\\'ll give the gift, of AI to all below!\\n\\n(Outro)\\nLangChain, LangChain, forever you will reign,\\nAnd ease the burden, and ease the pain,\\nOf building systems, complex and grand,\\nWith the power of language, close at hand!\\n', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 7, 'candidates_token_count': 497, 'total_token_count': 504, 'prompt_tokens_details': [{'modality': 1, 'token_count': 7}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 497}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.4734966193646252, 'model_name': 'gemini-2.0-flash-001'}, id='run-12b486b0-dc9f-466e-af55-172360de4547-0', usage_metadata={'input_tokens': 7, 'output_tokens': 497, 'total_tokens': 504})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "llm = ChatVertexAI(model_name=\"gemini-pro\")\n",
        "chain = prompt | llm\n",
        "\n",
        "question = \"Who was the president of the USA in 1994?\"\n",
        "print(chain.invoke({\"question\": question}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEbusefU4zV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838111448,
          "user_tz": -330,
          "elapsed": 2921,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "59100226-4ba2-446b-fec6-a417f234125e"
      },
      "id": "NnEbusefU4zV",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Bill Clinton was the president of the USA in 1994. He was inaugurated on January 20, 1993, and served two terms in office. His presidency was marked by a period of economic prosperity and peace, as well as by several scandals and controversies. He left office in January 2001, with an approval rating of 65%.' additional_kwargs={} response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.099609375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.037353515625}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1416015625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.068359375}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.4453125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.061767578125}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.30859375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.055908203125}], 'usage_metadata': {'prompt_token_count': 27, 'candidates_token_count': 79, 'total_token_count': 106, 'prompt_tokens_details': [{'modality': 1, 'token_count': 27}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 79}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.24270190468317346, 'model_name': 'gemini-pro'} id='run-be320c57-8cbf-413d-bed1-de4af2cb3689-0' usage_metadata={'input_tokens': 27, 'output_tokens': 79, 'total_tokens': 106}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "llm = ChatVertexAI(model_name=\"gemini-pro-vision\")\n",
        "# example\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"What's in this image?\",\n",
        "        },  # You can optionally provide text parts\n",
        "        {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSsL-ffKbbXXfOVlPHRGLi4TTMNVC93BS3lYg&s\"}},\n",
        "    ]\n",
        ")\n",
        "llm.invoke([message])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alScAKgVU5RR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838119136,
          "user_tz": -330,
          "elapsed": 2615,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d3a409a3-7f1a-420b-d5f9-73bf8958b8b3"
      },
      "id": "alScAKgVU5RR",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=' The image is a headshot of a man with dark hair, wearing a white shirt, dark vest, and striped tie.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0419921875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09130859375}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.15625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09033203125}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.056640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.06298828125}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1279296875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09423828125}], 'usage_metadata': {'prompt_token_count': 265, 'candidates_token_count': 24, 'total_token_count': 289, 'candidates_tokens_details': [{'modality': 1, 'token_count': 24}], 'cached_content_token_count': 0, 'prompt_tokens_details': [], 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.44030463695526123, 'model_name': 'gemini-pro-vision'}, id='run-a32744ab-14fb-4e1d-9053-d700c44db065-0', usage_metadata={'input_tokens': 265, 'output_tokens': 24, 'total_tokens': 289})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "embeddings.embed_query(\"hello, world!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gqEMLt6VSkW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838124736,
          "user_tz": -330,
          "elapsed": 743,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5b8f972d-bd12-48db-abfd-d3b58cf9f0b9"
      },
      "id": "1gqEMLt6VSkW",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014437370002269745,\n",
              " -0.022448306903243065,\n",
              " -0.05441752448678017,\n",
              " -0.0063039460219442844,\n",
              " -0.03377970680594444,\n",
              " -0.009890653192996979,\n",
              " 0.05721506103873253,\n",
              " 0.02759643644094467,\n",
              " 0.03676418960094452,\n",
              " 0.05071153864264488,\n",
              " -0.05302956700325012,\n",
              " 0.00407195370644331,\n",
              " 0.035264912992715836,\n",
              " -0.001106338226236403,\n",
              " -0.028692636638879776,\n",
              " -0.0223276074975729,\n",
              " -0.01600346900522709,\n",
              " 0.007004051469266415,\n",
              " -0.10984145104885101,\n",
              " 0.006073547061532736,\n",
              " 0.017101887613534927,\n",
              " -0.0008256578585132957,\n",
              " -0.026770014315843582,\n",
              " -0.05897821485996246,\n",
              " -0.004317032173275948,\n",
              " 0.014265161007642746,\n",
              " 0.0056959292851388454,\n",
              " 0.02586817368865013,\n",
              " 0.032467059791088104,\n",
              " 0.039141107350587845,\n",
              " -0.04069794714450836,\n",
              " 0.026864320039749146,\n",
              " -0.0076407333835959435,\n",
              " -0.03636273369193077,\n",
              " -0.0027094895485788584,\n",
              " 0.007745548617094755,\n",
              " -0.04779468849301338,\n",
              " 0.015406235121190548,\n",
              " 0.016143113374710083,\n",
              " -0.05967365950345993,\n",
              " -0.04062853008508682,\n",
              " 0.0251978300511837,\n",
              " 0.01382515113800764,\n",
              " 0.010017942637205124,\n",
              " 0.04733823612332344,\n",
              " -0.0404888354241848,\n",
              " 0.012498137541115284,\n",
              " -0.002250030403956771,\n",
              " 0.003998740576207638,\n",
              " -0.006360804662108421,\n",
              " 0.06064347177743912,\n",
              " 0.0013081871438771486,\n",
              " -0.07944478839635849,\n",
              " 0.03749680891633034,\n",
              " -0.008775094524025917,\n",
              " 0.010627268813550472,\n",
              " -0.040547046810388565,\n",
              " -0.049531545490026474,\n",
              " 0.1280539333820343,\n",
              " -0.025332724675536156,\n",
              " -0.02991877868771553,\n",
              " -0.03627987951040268,\n",
              " 0.04658764973282814,\n",
              " 0.022115636616945267,\n",
              " -0.044248029589653015,\n",
              " -0.019613640382885933,\n",
              " 0.005229499191045761,\n",
              " 0.015381584875285625,\n",
              " -0.03259550407528877,\n",
              " 0.011121591553092003,\n",
              " -0.05293276906013489,\n",
              " 0.011548848822712898,\n",
              " -0.018838420510292053,\n",
              " 0.00413490692153573,\n",
              " -0.04837260767817497,\n",
              " 0.004156722687184811,\n",
              " -0.016462497413158417,\n",
              " 0.023230375722050667,\n",
              " 0.015200232155621052,\n",
              " 0.0010908099357038736,\n",
              " -0.024820083752274513,\n",
              " 0.03342394530773163,\n",
              " 0.022497672587633133,\n",
              " 0.00735855009406805,\n",
              " 0.0028709617909044027,\n",
              " 0.008374519646167755,\n",
              " -0.010176019743084908,\n",
              " 0.03119533136487007,\n",
              " -0.029276259243488312,\n",
              " 0.029232291504740715,\n",
              " 0.04735928401350975,\n",
              " -0.01388903521001339,\n",
              " -0.0434834361076355,\n",
              " 0.00876708421856165,\n",
              " 0.04561656340956688,\n",
              " 0.0001153066914412193,\n",
              " -0.09497048705816269,\n",
              " -0.0693962350487709,\n",
              " 0.03504569083452225,\n",
              " 0.04694986343383789,\n",
              " -0.007287763990461826,\n",
              " -0.020630793645977974,\n",
              " 0.01303846761584282,\n",
              " -0.03683006763458252,\n",
              " 0.016625169664621353,\n",
              " 0.05453028529882431,\n",
              " -0.06749027222394943,\n",
              " 0.008470522239804268,\n",
              " -0.028787188231945038,\n",
              " -0.011394236236810684,\n",
              " 0.02942032925784588,\n",
              " -0.039913494139909744,\n",
              " 0.04858490079641342,\n",
              " 0.0037359301932156086,\n",
              " -0.038635045289993286,\n",
              " -0.06296472996473312,\n",
              " -0.08571498095989227,\n",
              " 0.022279268130660057,\n",
              " -0.03854569420218468,\n",
              " 0.00898228120058775,\n",
              " 0.02032461017370224,\n",
              " 0.03775225207209587,\n",
              " -0.0013910637935623527,\n",
              " 0.02815425582230091,\n",
              " 0.07378209382295609,\n",
              " -0.013580955564975739,\n",
              " 0.0377720445394516,\n",
              " -0.0001578844676259905,\n",
              " -0.026868917047977448,\n",
              " -0.036505963653326035,\n",
              " 0.049438927322626114,\n",
              " -0.04769553989171982,\n",
              " 0.027516748756170273,\n",
              " 0.03331219404935837,\n",
              " -0.05889976769685745,\n",
              " -0.04237525910139084,\n",
              " 0.03232092782855034,\n",
              " 0.004809072241187096,\n",
              " 0.013133405707776546,\n",
              " -0.011914254166185856,\n",
              " 0.019422641023993492,\n",
              " -0.0041384007781744,\n",
              " -0.031171545386314392,\n",
              " -0.009549777954816818,\n",
              " 0.022939300164580345,\n",
              " -0.04719191789627075,\n",
              " 0.0235923919826746,\n",
              " 0.038460683077573776,\n",
              " -0.0156107721850276,\n",
              " 0.00932516623288393,\n",
              " -0.00367669272236526,\n",
              " 0.012838361784815788,\n",
              " 0.039625708013772964,\n",
              " -0.0398966446518898,\n",
              " -0.025219853967428207,\n",
              " 0.02739407680928707,\n",
              " 0.047299448400735855,\n",
              " -0.06705502420663834,\n",
              " 0.0421605184674263,\n",
              " 0.02749129757285118,\n",
              " -0.026353079825639725,\n",
              " -0.054584089666604996,\n",
              " 0.013134765438735485,\n",
              " -0.023353926837444305,\n",
              " -0.010260087437927723,\n",
              " 0.02396959252655506,\n",
              " 0.00864213053137064,\n",
              " -0.0224748682230711,\n",
              " 0.009361529722809792,\n",
              " -0.048445843160152435,\n",
              " -0.01200445182621479,\n",
              " -0.049326714128255844,\n",
              " -0.021955382078886032,\n",
              " 0.03402440622448921,\n",
              " 0.020454268902540207,\n",
              " -0.013785511255264282,\n",
              " -0.03844089433550835,\n",
              " -0.00423766253516078,\n",
              " -0.026624245569109917,\n",
              " -0.07760514318943024,\n",
              " 0.11082632094621658,\n",
              " 0.029522307217121124,\n",
              " -0.002470841398462653,\n",
              " -0.05246322974562645,\n",
              " 0.01423998549580574,\n",
              " 0.0284881591796875,\n",
              " 0.005600738804787397,\n",
              " 0.05050385370850563,\n",
              " 0.07971125096082687,\n",
              " 0.04394742101430893,\n",
              " -0.04195599630475044,\n",
              " 0.0337798036634922,\n",
              " 0.004055395256727934,\n",
              " -0.009100519120693207,\n",
              " 0.03353108465671539,\n",
              " -0.006334980484098196,\n",
              " 0.1021404042840004,\n",
              " -0.03197631984949112,\n",
              " -0.022931795567274094,\n",
              " 0.006892969366163015,\n",
              " 0.033611323684453964,\n",
              " 0.04170284792780876,\n",
              " 0.0007716568070463836,\n",
              " -0.03603890910744667,\n",
              " 0.007637512870132923,\n",
              " 0.031418439000844955,\n",
              " -0.07216870039701462,\n",
              " -0.059137385338544846,\n",
              " 0.0471920482814312,\n",
              " 0.04786815866827965,\n",
              " -0.001331032020971179,\n",
              " -0.020640257745981216,\n",
              " 0.0038419996853917837,\n",
              " -0.03453705087304115,\n",
              " -0.0022345741745084524,\n",
              " 0.04843201860785484,\n",
              " 0.0811423733830452,\n",
              " -0.03550136834383011,\n",
              " 0.01869340054690838,\n",
              " 0.0041136834770441055,\n",
              " 0.025758789852261543,\n",
              " 0.04130629077553749,\n",
              " 0.02280290052294731,\n",
              " -0.009159821085631847,\n",
              " 0.061633963137865067,\n",
              " 0.031393080949783325,\n",
              " -0.02697327546775341,\n",
              " -0.024672981351614,\n",
              " -0.015385891310870647,\n",
              " -0.003469698829576373,\n",
              " -0.05407494306564331,\n",
              " 0.0275937058031559,\n",
              " -0.0388311967253685,\n",
              " 0.06983640789985657,\n",
              " 0.018968267366290092,\n",
              " 0.01615487039089203,\n",
              " 0.07651550322771072,\n",
              " 0.008644924499094486,\n",
              " -0.019243279471993446,\n",
              " 0.021094152703881264,\n",
              " -0.009452028200030327,\n",
              " -0.0924573764204979,\n",
              " 0.027571752667427063,\n",
              " 0.0051476978696882725,\n",
              " -0.007895327173173428,\n",
              " -0.04298708960413933,\n",
              " 0.012309223413467407,\n",
              " 0.022561578080058098,\n",
              " 0.04458993300795555,\n",
              " -0.05007428303360939,\n",
              " -0.07508265227079391,\n",
              " 0.02069089561700821,\n",
              " -0.04283444583415985,\n",
              " -0.0022161316592246294,\n",
              " -0.0170793067663908,\n",
              " -0.03929110988974571,\n",
              " 0.0008362802909687161,\n",
              " -0.03516578674316406,\n",
              " 0.012348649092018604,\n",
              " 0.008452247828245163,\n",
              " 0.05806034430861473,\n",
              " -0.049842361360788345,\n",
              " -0.0027547036297619343,\n",
              " -0.10161479562520981,\n",
              " -0.05118246376514435,\n",
              " -0.04744463786482811,\n",
              " 0.040536195039749146,\n",
              " 0.010237578302621841,\n",
              " -0.0042051938362419605,\n",
              " -0.0777243822813034,\n",
              " -0.002322250511497259,\n",
              " -0.04514544829726219,\n",
              " -0.02852388098835945,\n",
              " -0.012174263596534729,\n",
              " -0.027280181646347046,\n",
              " 0.014153030700981617,\n",
              " -0.03304304555058479,\n",
              " 0.0336262509226799,\n",
              " -0.07877933979034424,\n",
              " -0.031262364238500595,\n",
              " -0.015096037648618221,\n",
              " -0.013676643371582031,\n",
              " 0.0019521474605426192,\n",
              " 0.014938129112124443,\n",
              " -0.024814652279019356,\n",
              " -0.020695766434073448,\n",
              " 0.050323616713285446,\n",
              " 0.04761211946606636,\n",
              " -0.02046346105635166,\n",
              " -0.006339895073324442,\n",
              " 0.022207163274288177,\n",
              " -0.015619981102645397,\n",
              " 0.001856248825788498,\n",
              " -0.01974785141646862,\n",
              " 0.026608703657984734,\n",
              " 0.00969062652438879,\n",
              " 0.03703555837273598,\n",
              " 0.02534184232354164,\n",
              " 0.054445404559373856,\n",
              " 0.0021994865965098143,\n",
              " 0.010116882622241974,\n",
              " 0.053908880800008774,\n",
              " -0.04438955336809158,\n",
              " -0.0025143513921648264,\n",
              " -0.025058943778276443,\n",
              " -0.0028245942667126656,\n",
              " 0.016879389062523842,\n",
              " -0.040296971797943115,\n",
              " -0.020635133609175682,\n",
              " -0.01657234877347946,\n",
              " -0.007558815181255341,\n",
              " 0.025192178785800934,\n",
              " 0.009923419915139675,\n",
              " -0.01639995351433754,\n",
              " -0.05380692332983017,\n",
              " -0.001526283798739314,\n",
              " -0.10543882101774216,\n",
              " 0.003906459081918001,\n",
              " -0.06728874891996384,\n",
              " -0.04143652319908142,\n",
              " 0.07199399173259735,\n",
              " 0.025503356009721756,\n",
              " -0.07282472401857376,\n",
              " -0.03455931320786476,\n",
              " 0.005359513685107231,\n",
              " -0.045098092406988144,\n",
              " 0.037644993513822556,\n",
              " 0.013689464889466763,\n",
              " 0.004168287385255098,\n",
              " -0.007961547002196312,\n",
              " 0.015498276799917221,\n",
              " 0.018177829682826996,\n",
              " 0.011871369555592537,\n",
              " -0.06542963534593582,\n",
              " 0.002411642810329795,\n",
              " 0.07791675627231598,\n",
              " -0.025533350184559822,\n",
              " 0.03799337148666382,\n",
              " 0.053897444158792496,\n",
              " 0.07735394686460495,\n",
              " -0.013708421029150486,\n",
              " 0.04918336868286133,\n",
              " 0.04384520649909973,\n",
              " 0.037846606224775314,\n",
              " 0.020040525123476982,\n",
              " -0.0038538456428796053,\n",
              " 0.017658844590187073,\n",
              " 0.00345690012909472,\n",
              " -0.011244378983974457,\n",
              " -0.05829158052802086,\n",
              " 9.48174056247808e-05,\n",
              " 0.029633810743689537,\n",
              " 0.019752955064177513,\n",
              " -0.02157503180205822,\n",
              " -0.08031044900417328,\n",
              " 0.020156586542725563,\n",
              " 0.07734120637178421,\n",
              " -0.01135092694312334,\n",
              " -0.003788889152929187,\n",
              " -0.02828487940132618,\n",
              " 0.01645153947174549,\n",
              " 0.024273306131362915,\n",
              " -0.02271168865263462,\n",
              " 0.0377916619181633,\n",
              " -0.0547497496008873,\n",
              " 0.03825632855296135,\n",
              " -0.002101118676364422,\n",
              " 0.06539316475391388,\n",
              " 0.021380674093961716,\n",
              " -0.04569883272051811,\n",
              " 0.01982387714087963,\n",
              " 0.07192133367061615,\n",
              " -0.024845357984304428,\n",
              " -0.025767432525753975,\n",
              " -0.013154667802155018,\n",
              " -0.042409371584653854,\n",
              " -0.051455363631248474,\n",
              " -0.0032676896080374718,\n",
              " 0.049637697637081146,\n",
              " -0.08047319948673248,\n",
              " -0.03221238777041435,\n",
              " -0.006313594989478588,\n",
              " -0.05003108084201813,\n",
              " 0.002414020476862788,\n",
              " -0.06750468164682388,\n",
              " 0.06542155146598816,\n",
              " -0.037782713770866394,\n",
              " 0.01132438238710165,\n",
              " 0.005024576559662819,\n",
              " -0.020274264737963676,\n",
              " -0.024347173050045967,\n",
              " 0.06421323865652084,\n",
              " 0.04379541799426079,\n",
              " 0.04149913787841797,\n",
              " 0.03297749161720276,\n",
              " 0.022006938233971596,\n",
              " -0.06448035687208176,\n",
              " -0.0008402126841247082,\n",
              " 0.023360954597592354,\n",
              " 0.022617783397436142,\n",
              " -0.01752561330795288,\n",
              " 0.022512556985020638,\n",
              " 0.024554548785090446,\n",
              " -0.02452252246439457,\n",
              " 0.013042636215686798,\n",
              " -0.044922836124897,\n",
              " 0.04366488382220268,\n",
              " 0.033083874732255936,\n",
              " 0.06825070828199387,\n",
              " -0.014660438522696495,\n",
              " -0.03262467309832573,\n",
              " 0.05359703302383423,\n",
              " 0.0068482584320008755,\n",
              " 0.01610553450882435,\n",
              " -0.008133916184306145,\n",
              " -0.017228810116648674,\n",
              " -0.05402226746082306,\n",
              " 0.0188632532954216,\n",
              " 0.0056073847226798534,\n",
              " 0.003897900925949216,\n",
              " -0.03154303506016731,\n",
              " -0.04464643448591232,\n",
              " 0.017942184582352638,\n",
              " -0.036259543150663376,\n",
              " -0.02772456407546997,\n",
              " -0.054287102073431015,\n",
              " -0.03430608659982681,\n",
              " 0.03837870433926582,\n",
              " 0.038976091891527176,\n",
              " -0.0207357257604599,\n",
              " 0.0019212312763556838,\n",
              " 0.025604136288166046,\n",
              " -0.005036715883761644,\n",
              " -0.02437061071395874,\n",
              " -0.04202600196003914,\n",
              " 0.007696458604186773,\n",
              " -0.018558084964752197,\n",
              " 0.029987620189785957,\n",
              " 0.0015215410385280848,\n",
              " 0.032236382365226746,\n",
              " -0.03513496741652489,\n",
              " -0.007865147665143013,\n",
              " 0.02545025758445263,\n",
              " 0.05155649036169052,\n",
              " -0.03492337837815285,\n",
              " 0.05045333504676819,\n",
              " 0.03369579464197159,\n",
              " -0.029114162549376488,\n",
              " -0.012905029579997063,\n",
              " 0.012401831336319447,\n",
              " 0.006939533166587353,\n",
              " -0.01570681668817997,\n",
              " -0.00876644067466259,\n",
              " 0.013726652599871159,\n",
              " -0.03712503984570503,\n",
              " 0.038598015904426575,\n",
              " -0.028275001794099808,\n",
              " 0.04904782772064209,\n",
              " 0.023918859660625458,\n",
              " 0.0152649637311697,\n",
              " -0.0703505352139473,\n",
              " 0.03101488947868347,\n",
              " 0.07625623047351837,\n",
              " -0.038863446563482285,\n",
              " -0.02664828486740589,\n",
              " -0.0005211884854361415,\n",
              " -0.03155622258782387,\n",
              " -0.0010668833274394274,\n",
              " -0.017561370506882668,\n",
              " 0.07646509259939194,\n",
              " 0.052962496876716614,\n",
              " 0.028576819226145744,\n",
              " -0.009039638563990593,\n",
              " 0.005060876719653606,\n",
              " 0.024237796664237976,\n",
              " 0.025835910812020302,\n",
              " -0.012432405725121498,\n",
              " -0.009014340117573738,\n",
              " 0.001695582875981927,\n",
              " 0.028600530698895454,\n",
              " -0.008346037939190865,\n",
              " 0.0005829799338243902,\n",
              " -0.009436804801225662,\n",
              " 0.01713540218770504,\n",
              " 0.0866599902510643,\n",
              " -0.013830786570906639,\n",
              " -0.028829293325543404,\n",
              " 0.006266566924750805,\n",
              " 0.019206421449780464,\n",
              " -0.005919913295656443,\n",
              " -0.00598498759791255,\n",
              " 0.04806846007704735,\n",
              " 0.02136111445724964,\n",
              " 0.010063259862363338,\n",
              " -0.09503048658370972,\n",
              " 0.04716832935810089,\n",
              " 0.03979235514998436,\n",
              " 0.028024720028042793,\n",
              " -0.02071063220500946,\n",
              " 0.0049985419027507305,\n",
              " 0.03431234136223793,\n",
              " 0.0034444802440702915,\n",
              " 0.00692105945199728,\n",
              " -0.0024558785371482372,\n",
              " -0.05601250007748604,\n",
              " -0.024991123005747795,\n",
              " -0.02147137187421322,\n",
              " -0.04320547729730606,\n",
              " 0.018940221518278122,\n",
              " -0.005326675716787577,\n",
              " 0.0523565448820591,\n",
              " -0.01907079480588436,\n",
              " 0.04001406580209732,\n",
              " 0.021534796804189682,\n",
              " -0.005406741984188557,\n",
              " 0.0222015418112278,\n",
              " -0.0865752100944519,\n",
              " 0.030902033671736717,\n",
              " -0.03699615225195885,\n",
              " 0.0321119986474514,\n",
              " -0.06821747869253159,\n",
              " -0.023609792813658714,\n",
              " 0.009254803881049156,\n",
              " -0.03148842230439186,\n",
              " 0.01755262352526188,\n",
              " -0.020010504871606827,\n",
              " -0.029719259589910507,\n",
              " -0.02240338921546936,\n",
              " 0.052726540714502335,\n",
              " -0.020546214655041695,\n",
              " -0.001435192534700036,\n",
              " 0.00767839839681983,\n",
              " 0.020317327231168747,\n",
              " -0.004177647642791271,\n",
              " -0.025113597512245178,\n",
              " 0.028135858476161957,\n",
              " -0.028007684275507927,\n",
              " 0.040047843009233475,\n",
              " -0.0900791585445404,\n",
              " 0.047296617180109024,\n",
              " -0.01072430144995451,\n",
              " -0.014033133164048195,\n",
              " 0.01919187605381012,\n",
              " 0.01573150046169758,\n",
              " -0.0032157604582607746,\n",
              " 0.031441666185855865,\n",
              " -0.016849495470523834,\n",
              " 0.013871864415705204,\n",
              " -0.04001240059733391,\n",
              " 0.038995373994112015,\n",
              " 0.006165705621242523,\n",
              " -0.04666305333375931,\n",
              " -0.03663080185651779,\n",
              " 0.005139912012964487,\n",
              " 0.011677393689751625,\n",
              " -0.01932300254702568,\n",
              " -0.024587145075201988,\n",
              " -0.006693562958389521,\n",
              " -0.018286990001797676,\n",
              " 0.0002610542578622699,\n",
              " 0.04852096736431122,\n",
              " -0.03924410790205002,\n",
              " 0.015816597267985344,\n",
              " -0.010672561824321747,\n",
              " 0.04903590306639671,\n",
              " 0.03610529378056526,\n",
              " -0.012385264039039612,\n",
              " 0.05738260596990585,\n",
              " 0.011348949745297432,\n",
              " 0.012214203365147114,\n",
              " 0.013289718888700008,\n",
              " -0.00797269120812416,\n",
              " 0.033318694680929184,\n",
              " -0.040284447371959686,\n",
              " 0.026613933965563774,\n",
              " 0.014557413756847382,\n",
              " -0.07868897169828415,\n",
              " -0.024617891758680344,\n",
              " -0.0096836406737566,\n",
              " -0.000939599412959069,\n",
              " 0.018079714849591255,\n",
              " -0.016971800476312637,\n",
              " 0.10481966286897659,\n",
              " 0.03476908802986145,\n",
              " -0.030901223421096802,\n",
              " 0.009693712927401066,\n",
              " -0.010461610741913319,\n",
              " -0.052862174808979034,\n",
              " 0.038872089236974716,\n",
              " -0.0006881466833874583,\n",
              " 0.012060534209012985,\n",
              " 0.02130756340920925,\n",
              " -0.03411692753434181,\n",
              " 0.017826566472649574,\n",
              " 0.007732944097369909,\n",
              " 0.006094570737332106,\n",
              " 0.01423525158315897,\n",
              " 0.03635994717478752,\n",
              " -0.007827725261449814,\n",
              " -0.01279443223029375,\n",
              " -0.01913720741868019,\n",
              " -0.04511077702045441,\n",
              " 0.015010732226073742,\n",
              " -0.04736262559890747,\n",
              " 0.00863717868924141,\n",
              " -0.0032765227369964123,\n",
              " -0.055238302797079086,\n",
              " -0.019838061183691025,\n",
              " 0.029151124879717827,\n",
              " -0.018705159425735474,\n",
              " 0.010791640728712082,\n",
              " -0.011103499680757523,\n",
              " -0.012298738583922386,\n",
              " -0.013060121797025204,\n",
              " -0.11020629853010178,\n",
              " 0.026409700512886047,\n",
              " -0.02976924180984497,\n",
              " -0.025688016787171364,\n",
              " -0.05378856882452965,\n",
              " 0.013841943815350533,\n",
              " 0.02015508897602558,\n",
              " 0.022138562053442,\n",
              " 0.022895535454154015,\n",
              " 0.023619290441274643,\n",
              " -0.03957697004079819,\n",
              " -0.018647510558366776,\n",
              " 0.03396650403738022,\n",
              " 0.029077181592583656,\n",
              " 0.04093530774116516,\n",
              " 0.01695071905851364,\n",
              " -0.022648129612207413,\n",
              " 0.006812064442783594,\n",
              " 0.03637390211224556,\n",
              " 0.006535204593092203,\n",
              " -0.008084258064627647,\n",
              " -0.029174979776144028,\n",
              " -0.01494970265775919,\n",
              " 0.026226963847875595,\n",
              " -0.02814636379480362,\n",
              " -0.069582499563694,\n",
              " 0.006787067744880915,\n",
              " 0.021024035289883614,\n",
              " 0.05331145226955414,\n",
              " 0.0754929706454277,\n",
              " -0.040214356034994125,\n",
              " 0.015133229084312916,\n",
              " -0.007861452177166939,\n",
              " -0.011096778325736523,\n",
              " 0.03239351883530617,\n",
              " 0.029719756916165352,\n",
              " -0.02937253937125206,\n",
              " 0.030776668339967728,\n",
              " -0.036688316613435745,\n",
              " 0.009747528471052647,\n",
              " 0.028401866555213928,\n",
              " 0.016220252960920334,\n",
              " -0.03403887152671814,\n",
              " -0.04046601429581642,\n",
              " 0.056793827563524246,\n",
              " 0.016892746090888977,\n",
              " 0.006251515354961157,\n",
              " -0.05646742135286331,\n",
              " -0.030080795288085938,\n",
              " -0.014945155940949917,\n",
              " -0.01980830915272236,\n",
              " -0.05594826489686966,\n",
              " -0.03759276494383812,\n",
              " -0.012208307161927223,\n",
              " 0.000527585856616497,\n",
              " -0.0017004442634060979,\n",
              " -0.001779642654582858,\n",
              " -0.017181599512696266,\n",
              " -0.059302445501089096,\n",
              " -0.030873751267790794,\n",
              " 0.01564926467835903,\n",
              " -0.01847773790359497,\n",
              " 0.0349646620452404,\n",
              " -0.03008948266506195,\n",
              " -0.000450548657681793,\n",
              " 0.03664873540401459,\n",
              " -0.006344829220324755,\n",
              " -0.03510603308677673,\n",
              " 0.06630385667085648,\n",
              " -0.07617121189832687,\n",
              " -0.03082413040101528,\n",
              " -0.034370698034763336,\n",
              " -0.019759176298975945,\n",
              " -0.0348491296172142,\n",
              " 0.04598398879170418,\n",
              " -0.016222434118390083,\n",
              " 0.023576270788908005,\n",
              " 0.00826842337846756,\n",
              " -0.042855191975831985,\n",
              " 0.01580994203686714,\n",
              " -0.0774049386382103,\n",
              " 0.02888469025492668,\n",
              " -0.0035751378163695335,\n",
              " 0.044598933309316635,\n",
              " -0.022327646613121033,\n",
              " 0.006199788302183151,\n",
              " -0.0026436035986989737,\n",
              " -0.018099507316946983,\n",
              " -0.06585118919610977,\n",
              " 0.028113774955272675,\n",
              " 0.01565348356962204,\n",
              " 0.012827812694013119,\n",
              " 0.10099920630455017,\n",
              " 0.01653658226132393,\n",
              " -0.042607806622982025,\n",
              " -0.016075709834694862,\n",
              " -0.07531839609146118,\n",
              " -0.021616961807012558,\n",
              " 0.043602775782346725,\n",
              " 0.00867034774273634,\n",
              " 0.029450472444295883,\n",
              " 0.024017445743083954,\n",
              " -0.008583593182265759,\n",
              " 0.03309871628880501,\n",
              " -0.0181971974670887,\n",
              " 0.03786748647689819,\n",
              " -0.021297359839081764,\n",
              " 0.016857806593179703,\n",
              " 0.04944683983922005,\n",
              " 0.046616580337285995,\n",
              " 0.04260532557964325,\n",
              " -0.028869330883026123,\n",
              " -0.012115762569010258,\n",
              " 0.024386748671531677,\n",
              " -0.033678311854600906,\n",
              " 0.0789698138833046,\n",
              " -0.0010197979863733053,\n",
              " -0.02957523986697197,\n",
              " 0.008222687989473343,\n",
              " 0.006674273870885372,\n",
              " -0.007268789689987898,\n",
              " -0.004956758581101894,\n",
              " -0.017368225380778313,\n",
              " -0.046648651361465454,\n",
              " 0.005218192003667355,\n",
              " -0.01115158386528492,\n",
              " 0.003147389506921172,\n",
              " -0.025100694969296455,\n",
              " -0.05929412320256233,\n",
              " -0.004967849235981703,\n",
              " 0.017970219254493713,\n",
              " 0.01612071320414543,\n",
              " -0.041607845574617386,\n",
              " 0.06423714756965637,\n",
              " -0.018291201442480087,\n",
              " -0.07654911279678345,\n",
              " -0.06799376010894775,\n",
              " 0.0254670362919569,\n",
              " -0.009818685241043568,\n",
              " 0.025897277519106865,\n",
              " 0.023576894775032997,\n",
              " -0.015522542409598827,\n",
              " 0.03945136070251465,\n",
              " -0.02539973147213459,\n",
              " 0.0352792851626873,\n",
              " -0.0024435832165181637,\n",
              " 0.021968815475702286,\n",
              " 0.08716578781604767,\n",
              " -0.017783861607313156,\n",
              " 0.048415765166282654,\n",
              " -0.03049154207110405,\n",
              " -0.04688538238406181,\n",
              " -0.0028826119378209114,\n",
              " 0.06016811355948448]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "llm = VertexAI(\n",
        "    model_name=\"gemini-1.5-pro\",  # Must include the full version\n",
        "    max_output_tokens=1000,\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "question = \"Write a python function that checks if a string is a valid email address\"\n",
        "\n",
        "output = llm(question)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKyU6W_7VZuJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838340136,
          "user_tz": -330,
          "elapsed": 11477,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "feefda21-afdf-4b46-9221-c5f0f483301d"
      },
      "id": "bKyU6W_7VZuJ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import re\n",
            "\n",
            "def is_valid_email(email):\n",
            "  \"\"\"\n",
            "  Checks if a string is a valid email address using a regular expression.\n",
            "\n",
            "  Args:\n",
            "      email: The string to check.\n",
            "\n",
            "  Returns:\n",
            "      True if the string is a valid email address, False otherwise.\n",
            "  \"\"\"\n",
            "  regex = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
            "  match = re.match(regex, email)\n",
            "  return bool(match)\n",
            "\n",
            "# Example usage\n",
            "email1 = \"test@example.com\"\n",
            "email2 = \"invalid-email\"\n",
            "email3 = \"user.name+tag@example.co.uk\"\n",
            "\n",
            "print(f\"'{email1}' is a valid email: {is_valid_email(email1)}\")\n",
            "print(f\"'{email2}' is a valid email: {is_valid_email(email2)}\")\n",
            "print(f\"'{email3}' is a valid email: {is_valid_email(email3)}\")\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "1. **Import `re` module:** This line imports the regular expression module in Python, which is necessary for working with regular expressions.\n",
            "2. **Define `is_valid_email(email)` function:**\n",
            "   - Takes a single argument `email` which is the string you want to validate.\n",
            "   - Uses a regular expression `r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"` to define the pattern of a valid email address. This pattern allows for alphanumeric characters, periods, underscores, percentage signs, plus and minus signs before the \"@\" symbol, followed by the domain name (again with alphanumeric characters, periods, and hyphens), and ending with a dot followed by a top-level domain (2 or more characters).\n",
            "   - `re.match(regex, email)` attempts to match the regular expression `regex` from the beginning of the `email` string.\n",
            "   - `bool(match)` converts the match object (which is Truthy if there's a match and Falsy otherwise) to a boolean value (True or False).\n",
            "   - Returns `True` if the email matches the pattern, indicating a valid email address, and `False` otherwise.\n",
            "\n",
            "**Example Usage:**\n",
            "\n",
            "- The code demonstrates how to use the `is_valid_email` function with three different email strings. \n",
            "- It prints whether each email is valid or not based on the function's return value.\n",
            "\n",
            "This function provides a basic check for email validity. For more robust validation, you might consider using a dedicated email validation library or service.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "kzmkIqDWWISn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838384428,
          "user_tz": -330,
          "elapsed": 704,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "kzmkIqDWWISn",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(\"You are an AI assistant design to tell funny jokes. Do not answer any question that is not a joke.\"),\n",
        "    HumanMessage(\"Tell me a joke.\"),\n",
        "]"
      ],
      "metadata": {
        "id": "OWFIYnZzOW6S",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838387923,
          "user_tz": -330,
          "elapsed": 723,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "OWFIYnZzOW6S",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRHvxnk0OeQn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838441206,
          "user_tz": -330,
          "elapsed": 15,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "43042a9b-92e3-4d8c-b625-4dd334cde8dc"
      },
      "id": "zRHvxnk0OeQn",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't they play poker in the jungle? \n",
            "\n",
            "Too many cheetahs. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LangChain Agents"
      ],
      "metadata": {
        "id": "N2o_1WHNQy3i"
      },
      "id": "N2o_1WHNQy3i"
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"Prince\"\n",
        "txt = f\"Hello {username}\"\n",
        "\n",
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1obdqdTOg-g",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743838453495,
          "user_tz": -330,
          "elapsed": 712,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b5ab6cee-f3c4-4658-c785-9b8d2db54425"
      },
      "id": "P1obdqdTOg-g",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Prince\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import (\n",
        "    AgentExecutor,\n",
        "    create_openai_tools_agent\n",
        ")\n",
        "from langchain.tools import tool\n",
        "from langchain_core.tools import ToolException\n",
        "from typing import Literal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iftispEAQujN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743828268011,
          "user_tz": -330,
          "elapsed": 1366,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a6c75161-ac94-4d58-8959-59f7986685bb"
      },
      "id": "iftispEAQujN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/utilities/__init__.py:8: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_community.utilities.requests import (\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:775: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `TextRequestsWrapper` to V2.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "operator_type = Literal[\"add\", \"multiply\", \"substraction\", \"division\"]"
      ],
      "metadata": {
        "id": "QWZhKoIhQ6t4"
      },
      "id": "QWZhKoIhQ6t4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"Calculator-tool\", return_direct=False)\n",
        "def calculator(operator: operator_type, a: float, b: float) -> float:\n",
        "    \"\"\"A simple calculator tool that can add, multiply, substract, or divide two numbers.\"\"\"\n",
        "    if operator == \"add\":\n",
        "        return a + b\n",
        "    elif operator == \"multiply\":\n",
        "        return a * b\n",
        "    elif operator == \"substraction\":\n",
        "        return a - b\n",
        "    elif operator == \"division\":\n",
        "        return a / b\n",
        "    else:\n",
        "        raise ToolException(\"Invalid operator\")"
      ],
      "metadata": {
        "id": "qR04N_iqRFi2"
      },
      "id": "qR04N_iqRFi2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculator.name)\n",
        "print(calculator.description)\n",
        "print(calculator.return_direct)\n",
        "print(calculator.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ1YKhwxRH9y",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743828335337,
          "user_tz": -330,
          "elapsed": 693,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "158dc057-85ed-449b-f3f7-648af102ee1b"
      },
      "id": "tQ1YKhwxRH9y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculator-tool\n",
            "A simple calculator tool that can add, multiply, substract, or divide two numbers.\n",
            "False\n",
            "{'operator': {'enum': ['add', 'multiply', 'substraction', 'division'], 'title': 'Operator', 'type': 'string'}, 'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculator.run({\"operator\": \"add\", \"a\": 2, \"b\": 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR_UfGJURLT3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743828351504,
          "user_tz": -330,
          "elapsed": 706,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7f8a3e39-4736-4c9c-faa9-3c2db3421374"
      },
      "id": "VR_UfGJURLT3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Building A Tool Calling Agent"
      ],
      "metadata": {
        "id": "M26Ca5ABRST8"
      },
      "id": "M26Ca5ABRST8"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [calculator]"
      ],
      "metadata": {
        "id": "zkwB0si2RPPD"
      },
      "id": "zkwB0si2RPPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKJvZDdPRWvj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743828391404,
          "user_tz": -330,
          "elapsed": 10,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b2dd6f27-1d90-4bc4-b1be-fcbbedef1799"
      },
      "id": "gKJvZDdPRWvj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "You are a helpful assistant\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)"
      ],
      "metadata": {
        "id": "hH0f5p0ER96u"
      },
      "id": "hH0f5p0ER96u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "CYQq9ZgrSJAA"
      },
      "id": "CYQq9ZgrSJAA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke({\n",
        "    \"input\": \"What is the product of 2 and 3?\",\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDHuIKjwSOFT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743828611767,
          "user_tz": -330,
          "elapsed": 1376,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8ad5c8df-6c36-4034-da16-309604dfba7b"
      },
      "id": "ZDHuIKjwSOFT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Calculator-tool` with `{'operator': 'multiply', 'a': 2.0, 'b': 3.0}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m6.0\u001b[0m\u001b[32;1m\u001b[1;3mThe product of 2 and 3 is 6.0.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import (\n",
        "    AgentExecutor,\n",
        "    create_tool_calling_agent  # Use this instead of create_openai_tools_agent\n",
        ")\n",
        "from langchain.tools import tool\n",
        "from langchain_core.tools import ToolException\n",
        "from langchain_google_vertexai import ChatVertexAI  # Vertex AI integration\n",
        "from typing import Literal\n",
        "\n",
        "# Define a custom tool using the @tool decorator\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to someone.\"\"\"\n",
        "    if not name:\n",
        "        raise ToolException(\"Name cannot be empty.\")\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "# Load a prompt from LangChain Hub\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")  # Still works as-is for structure\n",
        "\n",
        "# Initialize Vertex AI model\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-2.0-flash-001\",  # or \"gemini-1.5-pro\" if available\n",
        "    temperature=0.2,\n",
        "    max_output_tokens=1024,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Create the agent\n",
        "agent = create_tool_calling_agent(llm=llm, tools=[say_hello], prompt=prompt)\n",
        "\n",
        "# AgentExecutor to run the agent\n",
        "agent_executor = AgentExecutor(agent=agent, tools=[say_hello], verbose=True)\n",
        "\n",
        "# Run an example\n",
        "response = agent_executor.invoke({\"input\": \"Say hello to Alice\"})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tujo8C3RZHU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743829297109,
          "user_tz": -330,
          "elapsed": 1451,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6c7c0bb5-f127-4f08-d154-8da7bfbf693c"
      },
      "id": "4Tujo8C3RZHU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `say_hello` with `{'name': 'Alice'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mHello, Alice!\u001b[0m\u001b[32;1m\u001b[1;3mHello, Alice!\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'Say hello to Alice', 'output': 'Hello, Alice!\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_openai_tools_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "5jG99IG6RwMu"
      },
      "id": "5jG99IG6RwMu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"pitchhubsmes\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "py_OwML8S7nV"
      },
      "id": "py_OwML8S7nV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the a specific Embeddings Model version\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prb_nyGWkhc4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833423362,
          "user_tz": -330,
          "elapsed": 815,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5809c526-e475-49f3-af69-3c99436e98cb"
      },
      "id": "Prb_nyGWkhc4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/__init__.py:219: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_community.document_loaders.youtube import (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector store with a sample text\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
        "\n",
        "vectorstore = InMemoryVectorStore.from_texts(\n",
        "    [text],\n",
        "    embedding=embeddings,\n",
        ")\n",
        "\n",
        "# Use the vectorstore as a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Retrieve the most similar text\n",
        "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
        "\n",
        "# show the retrieved document's content\n",
        "retrieved_documents[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "dRVg7gphklei",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833446257,
          "user_tz": -330,
          "elapsed": 763,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "33a8e5cc-a5ff-465c-f0c6-5ed338bd2570"
      },
      "id": "dRVg7gphklei",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is the framework for building context-aware reasoning applications'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_vector = embeddings.embed_query(text)\n",
        "print(str(single_vector)[:100])  # Show the first 100 characters of the vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zklF8hiNkrE_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833468163,
          "user_tz": -330,
          "elapsed": 738,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7a0b3fd6-c02b-48d2-f142-1e891ea7f74a"
      },
      "id": "zklF8hiNkrE_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02831101417541504, 0.022063178941607475, -0.07454229146242142, 0.006448323838412762, 0.001955120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    ChatPromptTemplate\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XkbYoQzkwaL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833535066,
          "user_tz": -330,
          "elapsed": 1454,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b40d7dc1-d6c0-4d3b-fae8-b9ee609346f3"
      },
      "id": "0XkbYoQzkwaL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
            "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEO4J_URI = \"neo4j+s://8a10c371.databases.neo4j.io\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"F1g4CVFjJfoZWWndxmmHYF9FUViFcHPlVN8OPisUxAQ\""
      ],
      "metadata": {
        "id": "xe2J9L8QlYgX"
      },
      "id": "xe2J9L8QlYgX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neo4j_graph_vector_index = Neo4jVector.from_existing_graph(\n",
        "    embedding=embeddings,\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USER,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    index_name=\"employee\",\n",
        "    node_label=\"Employee\",\n",
        "    text_node_properties=[\n",
        "        \"address\",\n",
        "        \"city\",\n",
        "        \"title\",\n",
        "        \"email\",\n",
        "        \"postalCode\"\n",
        "        \"note\",\n",
        "        \"fistName\",\n",
        "        \"lastName\",\n",
        "        \"region\"\n",
        "    ],\n",
        "    embedding_node_property=\"embedding\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6EHlCRJlAlC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833669521,
          "user_tz": -330,
          "elapsed": 6078,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d67c0ed3-3f52-4fa5-cf19-bc3b86c8bda0"
      },
      "id": "b6EHlCRJlAlC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.index.vector.createNodeIndex' has been replaced by 'CREATE VECTOR INDEX')} {position: line: 1, column: 1, offset: 0} for query: 'CALL db.index.vector.createNodeIndex($index_name,$node_label,$embedding_node_property,toInteger($embedding_dimension),$similarity_metric )'\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Employee`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = neo4j_graph_vector_index.similarity_search(\"Andrew\", k=2)"
      ],
      "metadata": {
        "id": "0R2GkugZlL8W"
      },
      "id": "0R2GkugZlL8W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8p9BjAzlsd_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833720414,
          "user_tz": -330,
          "elapsed": 726,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c13c8438-5957-41bc-dd7c-2e7aea689185"
      },
      "id": "i8p9BjAzlsd_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'employeeID': 3, 'hireDate': '1992-04-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000080540000424D80540000000000007600000028000000C0000000E0000000010004000000000000540000CE0E0000D80E0000000000', 'homePhone': '(206) 555-3412', 'photoPath': 'http://accweb/emmployees/leverling.bmp', 'country': 'USA', 'extension': 3355, 'postalCode': '98033', 'titleOfCourtesy': 'Ms.', 'birthDate': '1963-08-30 00:00:00.000', 'notes': 'Janet has a BS degree in chemistry from Boston College (1984). She has also completed a certificate program in food retailing management.  Janet was hired as a sales associate in 1991 and promoted to sales representative in February 1992.', 'firstName': 'Janet'}, page_content='\\naddress: 722 Moss Bay Blvd.\\ncity: Kirkland\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Leverling\\nregion: WA'),\n",
              " Document(metadata={'employeeID': 5, 'hireDate': '1993-10-17 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4848', 'photoPath': 'http://accweb/emmployees/buchanan.bmp', 'country': 'UK', 'extension': 3453, 'postalCode': 'SW1 8JR', 'titleOfCourtesy': 'Mr.', 'birthDate': '1955-03-04 00:00:00.000', 'notes': 'Steven Buchanan graduated from St. Andrews University in Scotland with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992 he spent 6 months in an orientation program at the Seattle office.', 'firstName': 'Steven'}, page_content='\\naddress: 14 Garrett Hill\\ncity: London\\ntitle: Sales Manager\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Buchanan\\nregion: Unknown')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for employee in result:\n",
        "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
        "\n",
        "    print(f\"\"\"\n",
        "          First name: {clearned_page_content.get('fistName')}\n",
        "          Last name: {clearned_page_content.get('lastName')}\n",
        "          Title: {clearned_page_content.get('title')}\n",
        "          country: {employee.metadata.get('country')}\n",
        "          \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaGG2eUGluAH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833755933,
          "user_tz": -330,
          "elapsed": 778,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "76d0b048-be2c-4138-e168-0376397e275c"
      },
      "id": "KaGG2eUGluAH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "          First name: \n",
            "          Last name: Leverling\n",
            "          Title: Sales Representative\n",
            "          country: USA\n",
            "          \n",
            "\n",
            "          First name: \n",
            "          Last name: Buchanan\n",
            "          Title: Sales Manager\n",
            "          country: UK\n",
            "          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "employee_details_chat_template_str = \"\"\"\n",
        "Your job is to use the provided employee data to answer\n",
        "questions about their roles, performance, and experiences\n",
        "within the company. Use the following context to answer questions.\n",
        "Be as detailed as possible, but don't make up any information that's\n",
        "not from the context. If you don't know an answer, say you don't know.\n",
        "\n",
        "Context: {context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8Fk3d1d9l2i3"
      },
      "id": "8Fk3d1d9l2i3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=employee_details_chat_template_str\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "9nFm_-ibl_ix"
      },
      "id": "9nFm_-ibl_ix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"question\"],\n",
        "        template=\"Can you provide details on: {question}?\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "JxeS9516mDjh"
      },
      "id": "JxeS9516mDjh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [employee_details_chat_system_prompt, human_prompt]"
      ],
      "metadata": {
        "id": "SkIAIEcwmGf7"
      },
      "id": "SkIAIEcwmGf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt = ChatPromptTemplate(\n",
        "    messages=messages,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "jcu4TIQJmKOj"
      },
      "id": "jcu4TIQJmKOj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=neo4j_graph_vector_index.as_retriever(),\n",
        "    chain_type=\"stuff\",\n",
        ")"
      ],
      "metadata": {
        "id": "x5gkAmLTmNnK"
      },
      "id": "x5gkAmLTmNnK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt"
      ],
      "metadata": {
        "id": "hAw-9mxnmQzb"
      },
      "id": "hAw-9mxnmQzb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa_chain.invoke(\"Give me profile details of Dodsworth.\")"
      ],
      "metadata": {
        "id": "fpqWDw53mUIf"
      },
      "id": "fpqWDw53mUIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.get(\"result\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRN_3tOgmXsA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743833907167,
          "user_tz": -330,
          "elapsed": 738,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4f616499-31d7-4367-a1a1-b4b39bc70742"
      },
      "id": "sRN_3tOgmXsA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are the details I have for Dodsworth:\n",
            "\n",
            "*   **Address:** 7 Houndstooth Rd.\n",
            "*   **City:** London\n",
            "*   **Title:** Sales Representative\n",
            "*   **Region:** Unknown\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain"
      ],
      "metadata": {
        "id": "XH6O-X63mbl9"
      },
      "id": "XH6O-X63mbl9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = Neo4jGraph(\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USER,\n",
        "    password=NEO4J_PASSWORD,\n",
        ")"
      ],
      "metadata": {
        "id": "LeJGTAWMmmgi"
      },
      "id": "LeJGTAWMmmgi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.refresh_schema()"
      ],
      "metadata": {
        "id": "ETX67VxYoF-K"
      },
      "id": "ETX67VxYoF-K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_generation_template = \"\"\"\n",
        "Task:\n",
        "Generate Cypher query for a Neo4j graph database.\n",
        "\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "\n",
        "Schema:\n",
        "{schema}\n",
        "\n",
        "Note:\n",
        "Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything other than\n",
        "for you to construct a Cypher statement. Do not include any text except\n",
        "the generated Cypher statement. Make sure the direction of the relationship is\n",
        "correct in your queries. Make sure you alias both entities and relationships\n",
        "properly. Do not run any queries that would add to or delete from\n",
        "the database. Make sure to alias all statements that follow as with\n",
        "statement (e.g. WITH c as customer, o.orderID as order_id).\n",
        "If you need to divide numbers, make sure to\n",
        "filter the denominator to be non-zero.\n",
        "\n",
        "Examples:\n",
        "# Retrieve the total number of orders placed by each customer.\n",
        "MATCH (c:Customer)-[o:ORDERED_BY]->(order:Order)\n",
        "RETURN c.customerID AS customer_id, COUNT(o) AS total_orders\n",
        "# List the top 5 products with the highest unit price.\n",
        "MATCH (p:Product)\n",
        "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
        "ORDER BY unit_price DESC\n",
        "LIMIT 5\n",
        "# Find all employees who have processed orders.\n",
        "MATCH (e:Employee)-[r:PROCESSED_BY]->(o:Order)\n",
        "RETURN e.employeeID AS employee_id, COUNT(o) AS orders_processed\n",
        "String category values:\n",
        "Use existing strings and values from the schema provided.\n",
        "\n",
        "The question is:\n",
        "{question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "loShP468ov8T"
      },
      "id": "loShP468ov8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_generation_prompt = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=cypher_generation_template\n",
        ")"
      ],
      "metadata": {
        "id": "BRXIYoOKpH1p"
      },
      "id": "BRXIYoOKpH1p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_generation_template_str = \"\"\"\n",
        "You are an assistant that takes the results from a Neo4j Cypher query and forms a human-readable response. The query results section contains the results of a Cypher query that was generated based on a user's natural language question. The provided information is authoritative; you must never question it or use your internal knowledge to alter it. Make the answer sound like a response to the question.\n",
        "\n",
        "Query Results:\n",
        "{context}\n",
        "Question:\n",
        "{question}\n",
        "If the provided information is empty, respond by stating that you don't know the answer. Empty information is indicated by: []\n",
        "If the information is not empty, you must provide an answer using the results. If the question involves a time duration, assume the query results are in units of days unless specified otherwise.\n",
        "When names are provided in the query results, such as hospital names, be cautious of any names containing commas or other punctuation. For example, 'Jones, Brown and Murray' is a single hospital name, not multiple hospitals. Ensure that any list of names is presented clearly to avoid ambiguity and make the full names easily identifiable.\n",
        "Never state that you lack sufficient information if data is present in the query results. Always utilize the data provided.\n",
        "Helpful Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cX_VUkhdpL_O"
      },
      "id": "cX_VUkhdpL_O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_generation_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"], template=qa_generation_template_str\n",
        ")"
      ],
      "metadata": {
        "id": "O9IKOxyGpOuc"
      },
      "id": "O9IKOxyGpOuc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    graph=graph,\n",
        "    top_k=10,\n",
        "    verbose=True,\n",
        "    validate_cypher=True,\n",
        "    qa_prompt=qa_generation_prompt,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    qa_llm=llm,  # e.g., another ChatVertexAI instance\n",
        "    cypher_llm=ChatVertexAI(model='gemini-1.5-pro', max_output_tokens=8192, temperature=0.0),\n",
        "    allow_dangerous_requests=True  # ⚠️ Required to bypass safety error\n",
        ")\n"
      ],
      "metadata": {
        "id": "y3ol0eOgpUlL"
      },
      "id": "y3ol0eOgpUlL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the most expensive product?\"\n",
        "response = cypher_chain.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMf2iyKRpck3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835495558,
          "user_tz": -330,
          "elapsed": 3488,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "dc3a8b74-fb5f-472c-9a72-6e29b32626f0"
      },
      "id": "KMf2iyKRpck3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (p:Product)\n",
            "RETURN p.productName AS productName, p.unitPrice AS unitPrice\n",
            "ORDER BY p.unitPrice DESC\n",
            "LIMIT 1\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'productName': 'Côte de Blaye', 'unitPrice': 263.5}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.get(\"result\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERmh6rktsetN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835514968,
          "user_tz": -330,
          "elapsed": 775,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "be61f9dd-7968-42ce-c1b7-c37df9d322e9"
      },
      "id": "ERmh6rktsetN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most expensive product is Côte de Blaye, with a unit price of 263.5.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"List the top 5 products with the highest unit price.\"\n",
        "response = cypher_chain.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7_9YmAlskF7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835533133,
          "user_tz": -330,
          "elapsed": 3576,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6fe1b270-3f9d-4fc4-e4b4-b768c76b95b7"
      },
      "id": "-7_9YmAlskF7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (p:Product)\n",
            "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
            "ORDER BY p.unitPrice DESC\n",
            "LIMIT 5\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}, {'product_name': 'Thüringer Rostbratwurst', 'unit_price': 123.79}, {'product_name': 'Mishi Kobe Niku', 'unit_price': 97.0}, {'product_name': \"Sir Rodney's Marmalade\", 'unit_price': 81.0}, {'product_name': 'Carnarvon Tigers', 'unit_price': 62.5}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.get(\"result\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFTBcwqlsn1V",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835544915,
          "user_tz": -330,
          "elapsed": 727,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9ca53472-3610-47af-9a72-1eedb78a70d4"
      },
      "id": "NFTBcwqlsn1V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 5 products with the highest unit price are: Côte de Blaye at 263.5, Thüringer Rostbratwurst at 123.79, Mishi Kobe Niku at 97.0, Sir Rodney's Marmalade at 81.0, and Carnarvon Tigers at 62.5.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give me more details on each shipper as well as how many orders they have shipped.\"\n",
        "response = cypher_chain.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzsJE3s1srcO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835562017,
          "user_tz": -330,
          "elapsed": 3127,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "10cb14a4-7a4e-4013-e2e4-7101f3a440b4"
      },
      "id": "kzsJE3s1srcO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (s:Shipper)<-[r:SHIPPED_BY]-(o:Order)\n",
            "RETURN s.shipperID AS shipper_id, s.companyName AS companyName, s.phone AS phone, COUNT(o) AS total_orders\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'shipper_id': 3, 'companyName': 'Federal Shipping', 'phone': '(503) 555-9931', 'total_orders': 87}, {'shipper_id': 1, 'companyName': 'Speedy Express', 'phone': '(503) 555-9831', 'total_orders': 67}, {'shipper_id': 2, 'companyName': 'United Package', 'phone': '(503) 555-3199', 'total_orders': 96}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.get(\"result\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD6d4INosvB8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835589335,
          "user_tz": -330,
          "elapsed": 735,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c3b1cf53-e315-4888-bc8a-eaa0e88e4da3"
      },
      "id": "lD6d4INosvB8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the details for each shipper and the number of orders they've shipped: Speedy Express (phone: (503) 555-9831) shipped 67 orders, United Package (phone: (503) 555-3199) shipped 96 orders, and Federal Shipping (phone: (503) 555-9931) shipped 87 orders.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Agents In GraphRAG Systems"
      ],
      "metadata": {
        "id": "GERjJfrds3fI"
      },
      "id": "GERjJfrds3fI"
    },
    {
      "cell_type": "code",
      "source": [
        "employee_details_chat_template_str = \"\"\"\n",
        "Your job is to use the provided employee data to answer\n",
        "questions about their roles, performance, and experiences\n",
        "within the company. Use the following context to answer questions.\n",
        "Be as detailed as possible, but don't make up any information that's\n",
        "not from the context. If you don't know an answer, say you don't know.\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rc9HZraKs0EZ"
      },
      "id": "Rc9HZraKs0EZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"employee-qa-tool\", return_direct=False)\n",
        "def employee_qa_tool(query: str) -> str:\n",
        "    \"\"\"Useful for answering questions about employees who work at a company.\"\"\"\n",
        "\n",
        "    employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"context\"],\n",
        "            template=employee_details_chat_template_str\n",
        "        )\n",
        "    )\n",
        "\n",
        "    human_prompt = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"question\"],\n",
        "            template=\"Can you provide details on: {question}?\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    messages = [employee_details_chat_system_prompt, human_prompt]\n",
        "\n",
        "    qa_prompt = ChatPromptTemplate(\n",
        "        messages=messages,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    llm = ChatVertexAI(model='gemini-1.5-flash-001')\n",
        "\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=neo4j_graph_vector_index.as_retriever(),\n",
        "        # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
        "        chain_type=\"stuff\",\n",
        "    )\n",
        "\n",
        "    qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt\n",
        "\n",
        "    response = qa_chain.invoke(query)\n",
        "\n",
        "    return response.get(\"result\")"
      ],
      "metadata": {
        "id": "WlqOthXOs9sf"
      },
      "id": "WlqOthXOs9sf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employee_qa_tool.invoke(\"What is the address of King?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "U625rxv9tLjx",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743836454717,
          "user_tz": -330,
          "elapsed": 1392,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "821043ff-151c-41c1-ad43-39ac74334d72"
      },
      "id": "U625rxv9tLjx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The address of King is Edgeham Hollow Winchester Way, London. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"general-qa-tool\", return_direct=False)\n",
        "def general_qa_tool(query: str) -> str:\n",
        "    \"\"\"Useful for answering general questions about orders, order details, shipper, customers, and products.\"\"\"\n",
        "    response = cypher_chain.invoke(query)\n",
        "\n",
        "    return response.get(\"result\")"
      ],
      "metadata": {
        "id": "2udlLOzktnvL"
      },
      "id": "2udlLOzktnvL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "general_qa_tool.invoke(\"What is the most expensive product?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "MmWejfbnt_-F",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835907220,
          "user_tz": -330,
          "elapsed": 2158,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "00afc52d-657f-49c7-dbc6-8102bcd617e5"
      },
      "id": "MmWejfbnt_-F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (p:Product)\n",
            "RETURN p.productName AS productName, p.unitPrice AS unitPrice\n",
            "ORDER BY unitPrice DESC\n",
            "LIMIT 1\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'productName': 'Côte de Blaye', 'unitPrice': 263.5}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The most expensive product is Côte de Blaye, with a unit price of 263.5.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating Agent"
      ],
      "metadata": {
        "id": "_WMrUW0juMKB"
      },
      "id": "_WMrUW0juMKB"
    },
    {
      "cell_type": "code",
      "source": [
        "agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ78JIRquDjM",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835965135,
          "user_tz": -330,
          "elapsed": 688,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9768c941-3d97-44de-b318-5e46fc48efea"
      },
      "id": "EJ78JIRquDjM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSawDwdpuSCr",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743835985837,
          "user_tz": -330,
          "elapsed": 741,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f6bd0624-6b39-4a08-bf43-65a900d21cd2"
      },
      "id": "BSawDwdpuSCr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "You are a helpful assistant\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [employee_qa_tool, general_qa_tool]"
      ],
      "metadata": {
        "id": "WBatN7M2uXFs"
      },
      "id": "WBatN7M2uXFs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_openai_tools_agent(llm, tools, agent_prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "EWV5y05_uaAW"
      },
      "id": "EWV5y05_uaAW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"What is the most expensive product?\"\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ssFtoGqueUG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743836034376,
          "user_tz": -330,
          "elapsed": 3298,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d7fc2f36-5e36-474d-a326-a3141ef979ce"
      },
      "id": "3ssFtoGqueUG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `general-qa-tool` with `{'query': 'What is the most expensive product?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (p:Product)\n",
            "RETURN p.productName AS productName, p.unitPrice AS unitPrice\n",
            "ORDER BY unitPrice DESC\n",
            "LIMIT 1\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'productName': 'Côte de Blaye', 'unitPrice': 263.5}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe most expensive product is Côte de Blaye, with a unit price of 263.5.\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mThe most expensive product is Côte de Blaye, with a unit price of 263.5.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the most expensive product?',\n",
              " 'output': 'The most expensive product is Côte de Blaye, with a unit price of 263.5.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"What is the address of Employee's Leverling?\"\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVWmr9E6uiS0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743836754330,
          "user_tz": -330,
          "elapsed": 677,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7a2910c5-70fb-46f1-b698-0377beb9e379"
      },
      "id": "HVWmr9E6uiS0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI do not have the ability to find the address of an employee. I can only answer questions about employees who work at a company.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What is the address of Employee's Buchanan?\",\n",
              " 'output': 'I do not have the ability to find the address of an employee. I can only answer questions about employees who work at a company.'}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNgKraEMwL9L"
      },
      "id": "yNgKraEMwL9L",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "neo4j_vertexai_gcp_agenticai"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}