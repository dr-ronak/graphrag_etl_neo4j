{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (0.1.0)\n",
      "Requirement already satisfied: openai==1.7.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: langchain-openai==0.0.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain-community==0.0.12 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (0.0.12)\n",
      "Requirement already satisfied: langchainhub==0.1.14 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (0.1.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (2.9.1)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (0.1.23)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (0.6.7)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (4.0.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (8.5.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (0.0.87)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (3.10.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain==0.1.0) (2.0.34)\n",
      "Requirement already satisfied: sniffio in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from openai==1.7.2) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from openai==1.7.2) (0.27.2)\n",
      "Requirement already satisfied: tqdm>4 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from openai==1.7.2) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from openai==1.7.2) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from openai==1.7.2) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from openai==1.7.2) (4.4.0)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain-openai==0.0.2) (0.5.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchainhub==0.1.14) (2.32.0.20240907)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.11.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.7.2) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.7.2) (3.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.7.2) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.7.2) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.7.2) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.0) (2.23.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai==0.0.2) (2024.7.24)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/prince/Desktop/content/tutorials/northwind_graph_rag/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install langchain==0.1.0 openai==1.7.2 langchain-openai==0.0.2 langchain-community==0.0.12 langchainhub==0.1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load In Envrironment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                 model=\"gpt-4o-mini\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Message Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are an AI assistant design to tell funny jokes. Do not answer any question that is not a joke.\"),\n",
    "    HumanMessage(\"Tell me a joke.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Prince\n"
     ]
    }
   ],
   "source": [
    "username = \"Prince\"\n",
    "txt = f\"Hello {username}\"\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me historical fact about the {event} in {location}.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me historical fact about the World War II in Europe.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(event=\"World War II\", location=\"Europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_str = \"\"\"You are a helpful AI assistant. Given the \n",
    "following context, answer the question. If the answer can not be \n",
    "found in the context, simply say you DO NOT KNOW.\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_promt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=system_message_str,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_str = \"Can you provide details on:  {question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=human_message_str,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [system_message_promt, human_message_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_prompt_template = ChatPromptTemplate(\n",
    "    messages=messages,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "context = \"France is a country in Europe. It's capital is Paris.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful AI assistant. Given the \\nfollowing context, answer the question. If the answer can not be \\nfound in the context, simply say you DO NOT KNOW.\\nContext: France is a country in Europe. It's capital is Paris.\\n\\nHuman: Can you provide details on:  What is the capital of France?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_prompt_template.format(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\n",
    "    chatbot_prompt_template.format(context=context, question=\"What is the capital of Kenya?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I DO NOT KNOW.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I DO NOT KNOW.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatbot_prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": question\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I DO NOT KNOW.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"What is the capital of Kenya?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    create_openai_tools_agent\n",
    ")\n",
    "from langchain.tools import tool\n",
    "from langchain_core.tools import ToolException\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_type = Literal[\"add\", \"multiply\", \"substraction\", \"division\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"Calculator-tool\", return_direct=False)\n",
    "def calculator(operator: operator_type, a: float, b: float) -> float:\n",
    "    \"\"\"A simple calculator tool that can add, multiply, substract, or divide two numbers.\"\"\"\n",
    "    if operator == \"add\":\n",
    "        return a + b\n",
    "    elif operator == \"multiply\":\n",
    "        return a * b\n",
    "    elif operator == \"substraction\":\n",
    "        return a - b\n",
    "    elif operator == \"division\":\n",
    "        return a / b\n",
    "    else:\n",
    "        raise ToolException(\"Invalid operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator-tool\n",
      "Calculator-tool(operator: Literal['add', 'multiply', 'substraction', 'division'], a: float, b: float) -> float - A simple calculator tool that can add, multiply, substract, or divide two numbers.\n",
      "False\n",
      "{'operator': {'title': 'Operator', 'enum': ['add', 'multiply', 'substraction', 'division'], 'type': 'string'}, 'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "print(calculator.name)\n",
    "print(calculator.description)\n",
    "print(calculator.return_direct)\n",
    "print(calculator.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.run({\"operator\": \"add\", \"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building A Tool Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator-tool` with `{'operator': 'multiply', 'a': 2, 'b': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m6.0\u001b[0m\u001b[32;1m\u001b[1;3mThe product of 2 and 3 is 6.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What is the product of 2 and 3?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language To Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Employee`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    }
   ],
   "source": [
    "neo4j_graph_vector_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "    url=os.getenv(\"NEO4J_URL\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    index_name=\"employee\",\n",
    "    node_label=\"Employee\",\n",
    "    text_node_properties=[\n",
    "        \"address\",\n",
    "        \"city\",\n",
    "        \"title\",\n",
    "        \"email\",\n",
    "        \"postalCode\"\n",
    "        \"note\",\n",
    "        \"fistName\",\n",
    "        \"lastName\",\n",
    "        \"region\"\n",
    "    ],\n",
    "    embedding_node_property=\"embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_graph_vector_index.similarity_search(\"Andrew\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\naddress: 14 Garrett Hill\\ncity: London\\ntitle: Sales Manager\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Buchanan\\nregion: Unknown', metadata={'employeeID': 5, 'hireDate': '1993-10-17 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4848', 'photoPath': 'http://accweb/emmployees/buchanan.bmp', 'country': 'UK', 'extension': 3453, 'postalCode': 'SW1 8JR', 'titleOfCourtesy': 'Mr.', 'birthDate': '1955-03-04 00:00:00.000', 'notes': 'Steven Buchanan graduated from St. Andrews University in Scotland with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992 he spent 6 months in an orientation program at the Seattle office.', 'firstName': 'Steven'}),\n",
       " Document(page_content='\\naddress: 507 20th Ave. E. Apt. 2A\\ncity: Seattle\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Davolio\\nregion: WA', metadata={'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.', 'firstName': 'Nancy'})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employeeID': 5, 'hireDate': '1993-10-17 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4848', 'photoPath': 'http://accweb/emmployees/buchanan.bmp', 'country': 'UK', 'extension': 3453, 'postalCode': 'SW1 8JR', 'titleOfCourtesy': 'Mr.', 'birthDate': '1955-03-04 00:00:00.000', 'notes': 'Steven Buchanan graduated from St. Andrews University in Scotland with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992 he spent 6 months in an orientation program at the Seattle office.', 'firstName': 'Steven'}\n"
     ]
    }
   ],
   "source": [
    "print(result[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_graph_vector_index.similarity_search(\n",
    "    \"Employee detail\", filter={\"country\": \"USA\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\naddress: 507 20th Ave. E. Apt. 2A\\ncity: Seattle\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Davolio\\nregion: WA', metadata={'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.', 'firstName': 'Nancy'}),\n",
       " Document(page_content='\\naddress: 722 Moss Bay Blvd.\\ncity: Kirkland\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Leverling\\nregion: WA', metadata={'employeeID': 3, 'hireDate': '1992-04-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000080540000424D80540000000000007600000028000000C0000000E0000000010004000000000000540000CE0E0000D80E0000000000', 'homePhone': '(206) 555-3412', 'photoPath': 'http://accweb/emmployees/leverling.bmp', 'country': 'USA', 'extension': 3355, 'postalCode': '98033', 'titleOfCourtesy': 'Ms.', 'birthDate': '1963-08-30 00:00:00.000', 'notes': 'Janet has a BS degree in chemistry from Boston College (1984). She has also completed a certificate program in food retailing management.  Janet was hired as a sales associate in 1991 and promoted to sales representative in February 1992.', 'firstName': 'Janet'}),\n",
       " Document(page_content='\\naddress: 7 Houndstooth Rd.\\ncity: London\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Dodsworth\\nregion: Unknown', metadata={'employeeID': 9, 'hireDate': '1994-11-15 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D16540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4444', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'UK', 'extension': 452, 'postalCode': 'WG2 7LT', 'titleOfCourtesy': 'Ms.', 'birthDate': '1966-01-27 00:00:00.000', 'notes': 'Anne has a BA degree in English from St. Lawrence College.  She is fluent in French and German.', 'firstName': 'Anne'}),\n",
       " Document(page_content='\\naddress: 14 Garrett Hill\\ncity: London\\ntitle: Sales Manager\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Buchanan\\nregion: Unknown', metadata={'employeeID': 5, 'hireDate': '1993-10-17 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(71) 555-4848', 'photoPath': 'http://accweb/emmployees/buchanan.bmp', 'country': 'UK', 'extension': 3453, 'postalCode': 'SW1 8JR', 'titleOfCourtesy': 'Mr.', 'birthDate': '1955-03-04 00:00:00.000', 'notes': 'Steven Buchanan graduated from St. Andrews University in Scotland with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992 he spent 6 months in an orientation program at the Seattle office.', 'firstName': 'Steven'})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          First name: \n",
      "          Last name: Davolio\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n",
      "\n",
      "          First name: \n",
      "          Last name: Leverling\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n",
      "\n",
      "          First name: \n",
      "          Last name: Dodsworth\n",
      "          Title: Sales Representative\n",
      "          country: UK\n",
      "          \n",
      "\n",
      "          First name: \n",
      "          Last name: Buchanan\n",
      "          Title: Sales Manager\n",
      "          country: UK\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for employee in result:\n",
    "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
    "    \n",
    "    print(f\"\"\"\n",
    "          First name: {clearned_page_content.get('fistName')}\n",
    "          Last name: {clearned_page_content.get('lastName')}\n",
    "          Title: {clearned_page_content.get('title')}\n",
    "          country: {employee.metadata.get('country')}\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_graph_vector_index.similarity_search(\n",
    "    \"Employee detail\", filter={\"country\": {\"$ne\": 'UK'}}, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\naddress: 507 20th Ave. E. Apt. 2A\\ncity: Seattle\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Davolio\\nregion: WA', metadata={'employeeID': 1, 'hireDate': '1992-05-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000020540000424D20540000000000007600000028000000C0000000DF0000000100040000000000A0530000CE0E0000D80E0000000000', 'homePhone': '(206) 555-9857', 'photoPath': 'http://accweb/emmployees/davolio.bmp', 'country': 'USA', 'extension': 5467, 'postalCode': '98122', 'titleOfCourtesy': 'Ms.', 'birthDate': '1948-12-08 00:00:00.000', 'notes': 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.', 'firstName': 'Nancy'}),\n",
       " Document(page_content='\\naddress: 722 Moss Bay Blvd.\\ncity: Kirkland\\ntitle: Sales Representative\\nemail: \\npostalCodenote: \\nfistName: \\nlastName: Leverling\\nregion: WA', metadata={'employeeID': 3, 'hireDate': '1992-04-01 00:00:00.000', 'photo': '0x151C2F00020000000D000E0014002100FFFFFFFF4269746D617020496D616765005061696E742E506963747572650001050000020000000700000050427275736800000000000000000080540000424D80540000000000007600000028000000C0000000E0000000010004000000000000540000CE0E0000D80E0000000000', 'homePhone': '(206) 555-3412', 'photoPath': 'http://accweb/emmployees/leverling.bmp', 'country': 'USA', 'extension': 3355, 'postalCode': '98033', 'titleOfCourtesy': 'Ms.', 'birthDate': '1963-08-30 00:00:00.000', 'notes': 'Janet has a BS degree in chemistry from Boston College (1984). She has also completed a certificate program in food retailing management.  Janet was hired as a sales associate in 1991 and promoted to sales representative in February 1992.', 'firstName': 'Janet'})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ne\n",
    "$lt\n",
    "$lte\n",
    "$gte\n",
    "$gt\n",
    "$in\n",
    "$like\n",
    "$ilke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          First name: \n",
      "          Last name: Davolio\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n",
      "\n",
      "          First name: \n",
      "          Last name: Leverling\n",
      "          Title: Sales Representative\n",
      "          country: USA\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for employee in result:\n",
    "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
    "    \n",
    "    print(f\"\"\"\n",
    "          First name: {clearned_page_content.get('fistName')}\n",
    "          Last name: {clearned_page_content.get('lastName')}\n",
    "          Title: {clearned_page_content.get('title')}\n",
    "          country: {employee.metadata.get('country')}\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_details_chat_template_str = \"\"\"\n",
    "Your job is to use the provided employee data to answer \n",
    "questions about their roles, performance, and experiences \n",
    "within the company. Use the following context to answer questions. \n",
    "Be as detailed as possible, but don't make up any information that's \n",
    "not from the context. If you don't know an answer, say you don't know.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=employee_details_chat_template_str\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"Can you provide details on: {question}?\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [employee_details_chat_system_prompt, human_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate(\n",
    "    messages=messages,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=neo4j_graph_vector_index.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke(\"Give me profile details of Dodsworth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Name: Dodsworth\n",
      "- Title: Sales Representative\n",
      "- Address: 7 Houndstooth Rd., London\n",
      "- Email: Not provided\n",
      "- Postal Code: Not provided\n",
      "- Region: Unknown\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URL\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_template = \"\"\"\n",
    "Task:\n",
    "Generate Cypher query for a Neo4j graph database.\n",
    "\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note:\n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything other than\n",
    "for you to construct a Cypher statement. Do not include any text except\n",
    "the generated Cypher statement. Make sure the direction of the relationship is\n",
    "correct in your queries. Make sure you alias both entities and relationships\n",
    "properly. Do not run any queries that would add to or delete from\n",
    "the database. Make sure to alias all statements that follow as with\n",
    "statement (e.g. WITH c as customer, o.orderID as order_id).\n",
    "If you need to divide numbers, make sure to\n",
    "filter the denominator to be non-zero.\n",
    "\n",
    "Examples:\n",
    "# Retrieve the total number of orders placed by each customer.\n",
    "MATCH (c:Customer)-[o:ORDERED_BY]->(order:Order)\n",
    "RETURN c.customerID AS customer_id, COUNT(o) AS total_orders\n",
    "# List the top 5 products with the highest unit price.\n",
    "MATCH (p:Product)\n",
    "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
    "ORDER BY unit_price DESC\n",
    "LIMIT 5\n",
    "# Find all employees who have processed orders.\n",
    "MATCH (e:Employee)-[r:PROCESSED_BY]->(o:Order)\n",
    "RETURN e.employeeID AS employee_id, COUNT(o) AS orders_processed\n",
    "String category values:\n",
    "Use existing strings and values from the schema provided. \n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    "    template=cypher_generation_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_template_str = \"\"\"\n",
    "You are an assistant that takes the results from a Neo4j Cypher query and forms a human-readable response. The query results section contains the results of a Cypher query that was generated based on a user's natural language question. The provided information is authoritative; you must never question it or use your internal knowledge to alter it. Make the answer sound like a response to the question.\n",
    "\n",
    "Query Results:\n",
    "{context}\n",
    "Question:\n",
    "{question}\n",
    "If the provided information is empty, respond by stating that you don't know the answer. Empty information is indicated by: []\n",
    "If the information is not empty, you must provide an answer using the results. If the question involves a time duration, assume the query results are in units of days unless specified otherwise.\n",
    "When names are provided in the query results, such as hospital names, be cautious of any names containing commas or other punctuation. For example, 'Jones, Brown and Murray' is a single hospital name, not multiple hospitals. Ensure that any list of names is presented clearly to avoid ambiguity and make the full names easily identifiable.\n",
    "Never state that you lack sufficient information if data is present in the query results. Always utilize the data provided.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], template=qa_generation_template_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    top_k=10,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    validate_cypher=True,\n",
    "    qa_prompt=qa_generation_prompt,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    qa_llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    cypher_llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the most expensive product?\"\n",
    "response = cypher_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most expensive product is \"Côte de Blaye\" with a unit price of 263.5.\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 5\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}, {'product_name': 'Thüringer Rostbratwurst', 'unit_price': 123.79}, {'product_name': 'Mishi Kobe Niku', 'unit_price': 97.0}, {'product_name': \"Sir Rodney's Marmalade\", 'unit_price': 81.0}, {'product_name': 'Carnarvon Tigers', 'unit_price': 62.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"List the top 5 products with the highest unit price.\"\n",
    "response = cypher_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 products with the highest unit prices are:\n",
      "1. Côte de Blaye - $263.5\n",
      "2. Thüringer Rostbratwurst - $123.79\n",
      "3. Mishi Kobe Niku - $97.0\n",
      "4. Sir Rodney's Marmalade - $81.0\n",
      "5. Carnarvon Tigers - $62.5\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (s:Shipper)<-[sh:SHIPPED_BY]-(o:Order)\n",
      "RETURN s.shipperID AS shipper_id, s.companyName AS company_name, s.phone AS phone, COUNT(o) AS total_orders_shipped\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'shipper_id': 3, 'company_name': 'Federal Shipping', 'phone': '(503) 555-9931', 'total_orders_shipped': 76}, {'shipper_id': 1, 'company_name': 'Speedy Express', 'phone': '(503) 555-9831', 'total_orders_shipped': 57}, {'shipper_id': 2, 'company_name': 'United Package', 'phone': '(503) 555-3199', 'total_orders_shipped': 80}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Give me more details on each shipper as well as how many orders they have shipped.\"\n",
    "response = cypher_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the details on each shipper along with the number of orders they have shipped:\n",
      "\n",
      "1. Shipper ID: 3\n",
      "   Company Name: Federal Shipping\n",
      "   Phone: (503) 555-9931\n",
      "   Total Orders Shipped: 76\n",
      "\n",
      "2. Shipper ID: 1\n",
      "   Company Name: Speedy Express\n",
      "   Phone: (503) 555-9831\n",
      "   Total Orders Shipped: 57\n",
      "\n",
      "3. Shipper ID: 2\n",
      "   Company Name: United Package\n",
      "   Phone: (503) 555-3199\n",
      "   Total Orders Shipped: 80\n",
      "\n",
      "These are the details you requested!\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents In GraphRAG Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_details_chat_template_str = \"\"\"\n",
    "Your job is to use the provided employee data to answer \n",
    "questions about their roles, performance, and experiences \n",
    "within the company. Use the following context to answer questions. \n",
    "Be as detailed as possible, but don't make up any information that's \n",
    "not from the context. If you don't know an answer, say you don't know.\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"employee-qa-tool\", return_direct=False)\n",
    "def employee_qa_tool(query: str) -> str:\n",
    "    \"\"\"Useful for answering questions about employees who work at a company.\"\"\"\n",
    "    \n",
    "    employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"context\"],\n",
    "            template=employee_details_chat_template_str\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    human_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\"question\"],\n",
    "            template=\"Can you provide details on: {question}?\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    messages = [employee_details_chat_system_prompt, human_prompt]\n",
    "    \n",
    "    qa_prompt = ChatPromptTemplate(\n",
    "        messages=messages,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=neo4j_graph_vector_index.as_retriever(),\n",
    "        # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
    "        chain_type=\"stuff\",\n",
    "    )\n",
    "    \n",
    "    qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt\n",
    "    \n",
    "    response = qa_chain.invoke(query)\n",
    "    \n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The address of Andrew is Edgeham Hollow Winchester Way in London.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_qa_tool.invoke(\"What is the address of Andrew?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"general-qa-tool\", return_direct=False)\n",
    "def general_qa_tool(query: str) -> str:\n",
    "    \"\"\"Useful for answering general questions about orders, order details, shipper, customers, and products.\"\"\"\n",
    "    response = cypher_chain.invoke(query)\n",
    "    \n",
    "    return response.get(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The most expensive product is Côte de Blaye, priced at $263.50.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_qa_tool.invoke(\"What is the most expensive product?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    create_openai_tools_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [employee_qa_tool, general_qa_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `general-qa-tool` with `{'query': 'most expensive product'}`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Product)\n",
      "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'product_name': 'Côte de Blaye', 'unit_price': 263.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe most expensive product is the \"Côte de Blaye\" with a unit price of 263.5.\u001b[0m\u001b[32;1m\u001b[1;3mThe most expensive product is the \"Côte de Blaye\" with a unit price of $263.5.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the most expensive product?',\n",
       " 'output': 'The most expensive product is the \"Côte de Blaye\" with a unit price of $263.5.'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is the most expensive product?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `employee-qa-tool` with `{'query': 'address of Dodsworth'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe address of Dodsworth is 7 Houndstooth Rd. in London.\u001b[0m\u001b[32;1m\u001b[1;3mThe address of Dodsworth is 7 Houndstooth Rd. in London.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the address of Dodsworth?',\n",
       " 'output': 'The address of Dodsworth is 7 Houndstooth Rd. in London.'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is the address of Dodsworth?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
