{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrVLCODM-c1x"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_eklf86-c1z",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874337115,
          "user_tz": -330,
          "elapsed": 18088,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3a0ca7cc-965c-40a1-985f-5b1bc7a9926e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.0\n",
            "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting openai==1.7.2\n",
            "  Downloading openai-1.7.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain-openai==0.0.2\n",
            "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
            "Collecting langchain-community==0.0.12\n",
            "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting langchainhub==0.1.14\n",
            "  Downloading langchainhub-0.1.14-py3-none-any.whl.metadata (478 bytes)\n",
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.20-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.74.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (1.33)\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.7.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.7.2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.7.2) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.7.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.7.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.7.2) (4.12.2)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai==0.0.2)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.14)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.89.0-py2.py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (2.19.0)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.19-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.18-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.17-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.13-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_google_vertexai-2.0.12-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.7.2)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_vertexai-2.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (4.25.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.2)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.7.2) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.7.2) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (1.6.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.7.2) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.7.2) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.7.2) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.0) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.7->langchain==0.1.0)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-1.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting types-protobuf<5.0.0.0,>=4.24.0.4 (from langchain-google-vertexai)\n",
            "  Downloading types_protobuf-4.25.0.20240417-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-1.0.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading langchain_google_vertexai-1.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading langchain_google_vertexai-0.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading langchain_google_vertexai-0.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-0.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-0.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_vertexai-0.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai==0.0.2) (2024.11.6)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.0.2-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_community-0.0.12-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\n",
            "Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_vertexai-0.0.7-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_protobuf-4.25.0.20240417-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: types-requests, types-protobuf, tenacity, packaging, mypy-extensions, typing-inspect, tiktoken, marshmallow, langchainhub, openai, langsmith, dataclasses-json, langchain-core, langchain-openai, langchain-community, langchain, langchain-google-vertexai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.4\n",
            "    Uninstalling openai-1.59.4:\n",
            "      Successfully uninstalled openai-1.59.4\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.2.10\n",
            "    Uninstalling langsmith-0.2.10:\n",
            "      Successfully uninstalled langsmith-0.2.10\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.29\n",
            "    Uninstalling langchain-core-0.3.29:\n",
            "      Successfully uninstalled langchain-core-0.3.29\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.14\n",
            "    Uninstalling langchain-0.3.14:\n",
            "      Successfully uninstalled langchain-0.3.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.3.5 requires langchain-core<0.4.0,>=0.3.29, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-0.1.0 langchain-community-0.0.12 langchain-core-0.1.23 langchain-google-vertexai-0.0.7 langchain-openai-0.0.2 langchainhub-0.1.14 langsmith-0.0.87 marshmallow-3.26.1 mypy-extensions-1.0.0 openai-1.7.2 packaging-23.2 tenacity-8.5.0 tiktoken-0.5.2 types-protobuf-4.25.0.20240417 types-requests-2.32.0.20250328 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install langchain==0.1.0 openai==1.7.2 langchain-openai==0.0.2 langchain-community==0.0.12 langchainhub==0.1.14  langchain-google-vertexai google-cloud-aiplatform\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-google-genai google-cloud-aiplatform\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lfQhdcE6TCOH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874353277,
          "user_tz": -330,
          "elapsed": 16167,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c2294405-9413-4a82-a801-a4b0cde06ab9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.74.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.12)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-2.0.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_genai-2.0.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-generativeai<0.6.0,>=0.5.2 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain)\n",
            "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (4.25.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
            "Collecting google-ai-generativelanguage==0.6.4 (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain)\n",
            "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.17-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading langchain_community-0.0.15-py3-none-any.whl.metadata (7.6 kB)\n",
            "  Downloading langchain_community-0.0.14-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Using cached langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.3.31-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.31-py3-none-any.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.3/358.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.52-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, zstandard, langsmith, langchain-core, langchain-text-splitters, google-ai-generativelanguage, langchain-google-genai, langchain\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.87\n",
            "    Uninstalling langsmith-0.0.87:\n",
            "      Successfully uninstalled langsmith-0.0.87\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.23\n",
            "    Uninstalling langchain-core-0.1.23:\n",
            "      Successfully uninstalled langchain-core-0.1.23\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.10\n",
            "    Uninstalling google-ai-generativelanguage-0.6.10:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.10\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.1.0\n",
            "    Uninstalling langchain-0.1.0:\n",
            "      Successfully uninstalled langchain-0.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.3 requires google-ai-generativelanguage==0.6.10, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\n",
            "langchain-community 0.0.12 requires langchain-core<0.2,>=0.1.9, but you have langchain-core 0.3.52 which is incompatible.\n",
            "langchain-community 0.0.12 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.3.31 which is incompatible.\n",
            "langchain-google-vertexai 0.0.7 requires langchain-core<0.2,>=0.1.23, but you have langchain-core 0.3.52 which is incompatible.\n",
            "langchain-openai 0.0.2 requires langchain-core<0.2,>=0.1.7, but you have langchain-core 0.3.52 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain-0.3.23 langchain-core-0.3.52 langchain-google-genai-2.1.3 langchain-text-splitters-0.3.8 langsmith-0.3.31 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ba1c7339f85049f28c17f82c136ed02c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQA_qDQg_rio",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874359843,
          "user_tz": -330,
          "elapsed": 6573,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "fe17a9f8-92e5-49d3-d50f-4dedfbae805d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.12)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.6.17)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.25.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: httpx-sse, pydantic-settings, langchain_community\n",
            "  Attempting uninstall: langchain_community\n",
            "    Found existing installation: langchain-community 0.0.12\n",
            "    Uninstalling langchain-community-0.0.12:\n",
            "      Successfully uninstalled langchain-community-0.0.12\n",
            "Successfully installed httpx-sse-0.4.0 langchain_community-0.3.21 pydantic-settings-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "#from langchain_google_vertexai import VertexChatAI\n",
        "import vertexai\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from datetime import datetime\n",
        "import json"
      ],
      "metadata": {
        "id": "XeiE0uRYF3tF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874373851,
          "user_tz": -330,
          "elapsed": 14013,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERTEX_AI_PROJECT = \"pitchhubsmes\"\n",
        "VERTEX_AI_LOCATION = \"us-central1\"\n",
        "\n",
        "vertexai.init(project=VERTEX_AI_PROJECT, location=VERTEX_AI_LOCATION)\n",
        "llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", GOOGLE_API_KEY=\"AIzaSyCs5HXFE9ATRdHzA-DwsDgZcv8NzeQFsUw\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRK71QlGGjMA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874909641,
          "user_tz": -330,
          "elapsed": 726,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e69cb2c3-0e46-4ff9-824c-9a0b0a99ef8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'GOOGLE_API_KEY' provided to ChatGoogleGenerativeAI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "import vertexai\n",
        "\n",
        "# Initialize Vertex AI with your project and region\n",
        "vertexai.init(project=\"pitchhubsmes\", location=\"us-central1\")\n"
      ],
      "metadata": {
        "id": "4jGi3vRaRl9M",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874919464,
          "user_tz": -330,
          "elapsed": 615,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an LLM object for Gemini model (use the latest version as needed)\n",
        "llm = GenerativeModel(\"gemini-1.5-flash\")  # or \"gemini-1.0-pro\", \"gemini-1.5-pro\", etc.\n"
      ],
      "metadata": {
        "id": "Tqcxyq7iRpVQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874922107,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.generate_content(\"Explain the concept of Large Language Models in simple terms.\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3qAYBhjRsqH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874927361,
          "user_tz": -330,
          "elapsed": 2254,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "87e58da8-fb5e-449a-ce1d-aa75a060a74d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine a really smart kid who has read *every single book in the world*. They know all the stories, all the facts, and all the ways words can be used.\n",
            "\n",
            "That's kind of like a Large Language Model (LLM). \n",
            "\n",
            "Here's how it works:\n",
            "\n",
            "* **They're trained on massive amounts of text data.** This is like the kid reading all those books.\n",
            "* **They learn patterns and relationships between words.**  They figure out which words go together and how they make sense.\n",
            "* **They can then generate text, translate languages, write different kinds of creative content, and answer questions.**  Just like the kid can tell you a story, write a poem, or answer a question about history.\n",
            "\n",
            "**Think of them as superpowered word machines!** They can understand and generate human language in amazing ways. \n",
            "\n",
            "**Here are some examples of LLMs you might have heard of:**\n",
            "\n",
            "* **ChatGPT:** A model that can chat with you, answer your questions, and even write creative text formats like poems, code, scripts, musical pieces, email, letters, etc.\n",
            "* **Bard:** Another chatbot that can provide summaries of factual topics or create stories.\n",
            "* **GPT-3:** This is the model that ChatGPT is built on. It's one of the most powerful language models available.\n",
            "\n",
            "**Even though they're very powerful, it's important to remember:**\n",
            "\n",
            "* **LLMs are still machines.** They don't have real understanding or consciousness, they just know how to manipulate words.\n",
            "* **They can sometimes make mistakes.** They may give you incorrect information or generate text that doesn't make sense.\n",
            "\n",
            "Overall, LLMs are fascinating tools that are changing the way we interact with technology. They have the potential to revolutionize many aspects of our lives. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from typing import List\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "import vertexai\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=\"pitchhubsmes\", location=\"us-central1\")\n",
        "\n",
        "\n",
        "class VertexAIGeminiChat(BaseChatModel):\n",
        "    def __init__(self, model_name=\"gemini-1.5-flash\", **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = GenerativeModel(model_name)\n",
        "\n",
        "    def _convert_messages_to_prompt(self, messages: List):\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt += f\"[SYSTEM]: {msg.content}\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"[USER]: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"[AI]: {msg.content}\\n\"\n",
        "        return prompt\n",
        "\n",
        "    def _call(self, messages: List, **kwargs) -> str:\n",
        "        prompt = self._convert_messages_to_prompt(messages)\n",
        "        response = self.model.generate_content(prompt)\n",
        "        return response.text\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vertexai-gemini\"\n"
      ],
      "metadata": {
        "id": "uz5welsQS3gj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874931943,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Use your custom Vertex AI LLM wrapper\n",
        "llm = VertexAIGeminiChat()\n",
        "\n",
        "# Optional tool (you can add any custom tools)\n",
        "def joke_tool(_):\n",
        "    return \"Why do programmers prefer dark mode? Because light attracts bugs!\"\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"JokeTool\",\n",
        "        func=joke_tool,\n",
        "        description=\"Tells a random programming joke.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Create LangChain Agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Use the agent\n",
        "response = agent.run(\"Tell me a programming joke.\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6WV5PI5dTvBK",
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875041311,
          "user_tz": -330,
          "elapsed": 9,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "cf51b461-1ba4-4956-ba62-bf3d5eb09e63"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Can't instantiate abstract class VertexAIGeminiChat with abstract method _generate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-62f3a360e6c0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use your custom Vertex AI LLM wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVertexAIGeminiChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Optional tool (you can add any custom tools)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class VertexAIGeminiChat with abstract method _generate"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3blA39n-c11"
      },
      "source": [
        "### Load In Envrironment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z2wRN6Lm-c12",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874951631,
          "user_tz": -330,
          "elapsed": 616,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0aIyYFFS2qm",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874373852,
          "user_tz": -330,
          "elapsed": 13,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHpcREDl-c12",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744874954919,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7103eb14-e391-41c4-dbdd-af730e06ad59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cannot find .env file\n"
          ]
        }
      ],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7_v2AOJ-c12",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874373853,
          "user_tz": -330,
          "elapsed": 13,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIOi-CBe-c13",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874373853,
          "user_tz": -330,
          "elapsed": 13,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "#                  model=\"gpt-4o-mini\"\n",
        "#                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "KTm6riLK-c13",
        "executionInfo": {
          "status": "error",
          "timestamp": 1744874958395,
          "user_tz": -330,
          "elapsed": 638,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "60995931-b85e-46bd-9ec9-962a479f07f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GenerativeModel' object has no attribute 'invoke'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2268c7411388>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello there!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'GenerativeModel' object has no attribute 'invoke'"
          ]
        }
      ],
      "source": [
        "llm.invoke(\"Hello there!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nM9VHzj-c13"
      },
      "source": [
        "### Working With Message Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s54jLGKN-c14",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875050352,
          "user_tz": -330,
          "elapsed": 722,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2lvORTPI-c14",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875052302,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(\"You are an AI assistant design to tell funny jokes. Do not answer any question that is not a joke.\"),\n",
        "    HumanMessage(\"Tell me a joke.\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "YNnTIpUg-c15",
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875054933,
          "user_tz": -330,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "23255ad1-7127-4fe4-ad14-557ab783d6ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Unexpected item type: content='You are an AI assistant design to tell funny jokes. Do not answer any question that is not a joke.' additional_kwargs={} response_metadata={}.Only types that represent a single Content or a single Part are supported here.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2a3e81e7c917>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m             )\n\u001b[1;32m    618\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             return self._generate_content(\n\u001b[0m\u001b[1;32m    620\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mA\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mGenerationResponse\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \"\"\"\n\u001b[0;32m--> 736\u001b[0;31m         request = self._prepare_request(\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_prepare_request\u001b[0;34m(self, contents, model, generation_config, safety_settings, tools, tool_config, system_instruction, labels)\u001b[0m\n\u001b[1;32m    480\u001b[0m         )\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_content_types_to_gapic_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mgapic_system_instruction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgapic_content_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_content_types_to_gapic_contents\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;31m# or a value that can be converted to a *single* Content object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_to_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_to_content\u001b[0;34m(value, role)\u001b[0m\n\u001b[1;32m   2882\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"A list of Content objects is not supported here: {items}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m   2885\u001b[0m                 \u001b[0;34mf\"Unexpected item type: {item}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m                 \u001b[0;34m\"Only types that represent a single Content or a single Part are supported here.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected item type: content='You are an AI assistant design to tell funny jokes. Do not answer any question that is not a joke.' additional_kwargs={} response_metadata={}.Only types that represent a single Content or a single Part are supported here."
          ]
        }
      ],
      "source": [
        "response = llm.generate_content(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQUXQuQ3-c16"
      },
      "source": [
        "### Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VFV8Lyfu-c16",
        "outputId": "64ba64f6-aaaf-49c8-d12f-362bcb744718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875059660,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Prince\n"
          ]
        }
      ],
      "source": [
        "username = \"Prince\"\n",
        "txt = f\"Hello {username}\"\n",
        "\n",
        "print(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "R_bB0mE0-c16",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875062951,
          "user_tz": -330,
          "elapsed": 668,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GUWeTxS4-c17",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875064980,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"Tell me historical fact about the {event} in {location}.\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X8UERj80-c17",
        "outputId": "3dbefad6-9b09-4421-bd2d-ac4068c5aa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875068288,
          "user_tz": -330,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me historical fact about the World War II in Europe.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "prompt_template.format(event=\"World War II\", location=\"Europe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XD71bemb-c18",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875070941,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K0gQYdzO-c19",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875075117,
          "user_tz": -330,
          "elapsed": 717,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "system_message_str = \"\"\"You are a helpful AI assistant. Given the\n",
        "following context, answer the question. If the answer can not be\n",
        "found in the context, simply say you DO NOT KNOW.\n",
        "Context: {context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OcaREgxK-c19",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875078281,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "system_message_promt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=system_message_str,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2NUOrZWw-c19",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875080396,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "human_message_str = \"Can you provide details on:  {question}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "v1FwDbg_-c1-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875083932,
          "user_tz": -330,
          "elapsed": 619,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"question\"],\n",
        "        template=human_message_str,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4C6ZBEnN-c1-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875087207,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "messages = [system_message_promt, human_message_prompt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "u3PUacr4-c1-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875089726,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "chatbot_prompt_template = ChatPromptTemplate(\n",
        "    messages=messages,\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DcZlPBzd-c1-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875092244,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "question = \"What is the capital of France?\"\n",
        "context = \"France is a country in Europe. It's capital is Paris.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PuNX8PT1-c1-",
        "outputId": "b317e64b-9713-4123-b8c3-656a17db5877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875096131,
          "user_tz": -330,
          "elapsed": 8,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"System: You are a helpful AI assistant. Given the\\nfollowing context, answer the question. If the answer can not be\\nfound in the context, simply say you DO NOT KNOW.\\nContext: France is a country in Europe. It's capital is Paris.\\n\\nHuman: Can you provide details on:  What is the capital of France?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "chatbot_prompt_template.format(context=context, question=question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lMNoKuRw-c1_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875098797,
          "user_tz": -330,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "21971e57-44e8-48b6-a21b-30a18982dfe8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GenerativeModel' object has no attribute 'invoke'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-50cd72f453ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = llm.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mchatbot_prompt_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"What is the capital of Kenya?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GenerativeModel' object has no attribute 'invoke'"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(\n",
        "    chatbot_prompt_template.format(context=context, question=\"What is the capital of Kenya?\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iFXZGogP-c1_",
        "outputId": "74fd324c-145a-4ff7-cbaf-54c0d2eda475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875105022,
          "user_tz": -330,
          "elapsed": 619,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "candidates {\n",
              "  content {\n",
              "    role: \"model\"\n",
              "    parts {\n",
              "      text: \"Imagine a really smart kid who has read *every single book in the world*. They know all the stories, all the facts, and all the ways words can be used.\\n\\nThat\\'s kind of like a Large Language Model (LLM). \\n\\nHere\\'s how it works:\\n\\n* **They\\'re trained on massive amounts of text data.** This is like the kid reading all those books.\\n* **They learn patterns and relationships between words.**  They figure out which words go together and how they make sense.\\n* **They can then generate text, translate languages, write different kinds of creative content, and answer questions.**  Just like the kid can tell you a story, write a poem, or answer a question about history.\\n\\n**Think of them as superpowered word machines!** They can understand and generate human language in amazing ways. \\n\\n**Here are some examples of LLMs you might have heard of:**\\n\\n* **ChatGPT:** A model that can chat with you, answer your questions, and even write creative text formats like poems, code, scripts, musical pieces, email, letters, etc.\\n* **Bard:** Another chatbot that can provide summaries of factual topics or create stories.\\n* **GPT-3:** This is the model that ChatGPT is built on. It\\'s one of the most powerful language models available.\\n\\n**Even though they\\'re very powerful, it\\'s important to remember:**\\n\\n* **LLMs are still machines.** They don\\'t have real understanding or consciousness, they just know how to manipulate words.\\n* **They can sometimes make mistakes.** They may give you incorrect information or generate text that doesn\\'t make sense.\\n\\nOverall, LLMs are fascinating tools that are changing the way we interact with technology. They have the potential to revolutionize many aspects of our lives. \\n\"\n",
              "    }\n",
              "  }\n",
              "  avg_logprobs: -0.443361297367126\n",
              "  finish_reason: STOP\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_HATE_SPEECH\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.13671875\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.133789062\n",
              "  }\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.0255126953\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.0454101562\n",
              "  }\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_HARASSMENT\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.203125\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.106933594\n",
              "  }\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.048828125\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.0583496094\n",
              "  }\n",
              "}\n",
              "model_version: \"gemini-1.5-flash-001\"\n",
              "usage_metadata {\n",
              "  prompt_token_count: 11\n",
              "  candidates_token_count: 381\n",
              "  total_token_count: 392\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "khnBlgE7-c1_",
        "outputId": "80703722-ca47-4fed-a87b-2b4b2872f747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875113389,
          "user_tz": -330,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GenerationResponse' object has no attribute 'content'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-3397cce000c3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'GenerationResponse' object has no attribute 'content'"
          ]
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbkBpgSz-c1_"
      },
      "source": [
        "### LangChain Expression Language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2yBM_eb1-c2A",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875117955,
          "user_tz": -330,
          "elapsed": 641,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "O4jRD4zh-c2A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875120661,
          "user_tz": -330,
          "elapsed": 617,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7f498714-62cf-4a53-fc1a-15daf8aa2027"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'vertexai.preview.generative_models.GenerativeModel'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-273cc499353a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatbot_prompt_template\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    572\u001b[0m     ) -> RunnableSerializable[Input, Other]:\n\u001b[1;32m    573\u001b[0m         \u001b[0;34m\"\"\"Compose this Runnable with another object to create a RunnableSequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRunnableSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     def __ror__(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5916\u001b[0m         \u001b[0;34mf\"Instead got an unsupported type: {type(thing)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5917\u001b[0m     )\n\u001b[0;32m-> 5918\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'vertexai.preview.generative_models.GenerativeModel'>"
          ]
        }
      ],
      "source": [
        "chain = chatbot_prompt_template | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "z_EPx9-C-c2A",
        "outputId": "e3aa08da-a349-4809-a42c-5b131bf4c0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875123763,
          "user_tz": -330,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'chain' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d8d03689499c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chain.invoke({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chain' is not defined"
          ]
        }
      ],
      "source": [
        "chain.invoke({\n",
        "    \"context\": context,\n",
        "    \"question\": question\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ISx35CDW-c2B",
        "outputId": "91549baa-5561-4892-9626-ae935c8f8b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875127361,
          "user_tz": -330,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'chain' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d199db9a9306>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chain.invoke({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"What is the capital of Kenya?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chain' is not defined"
          ]
        }
      ],
      "source": [
        "chain.invoke({\n",
        "    \"context\": context,\n",
        "    \"question\": \"What is the capital of Kenya?\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4bSqbLk-c2B"
      },
      "source": [
        "### LangChain Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1CLCAhCU-c2B",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875131690,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import (\n",
        "    AgentExecutor,\n",
        "    create_openai_tools_agent\n",
        ")\n",
        "from langchain.tools import tool\n",
        "from langchain_core.tools import ToolException\n",
        "from typing import Literal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AFangBrr-c2B",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744875134300,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "operator_type = Literal[\"add\", \"multiply\", \"substraction\", \"division\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkiMMZp4-c2B",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 22,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "@tool(\"Calculator-tool\", return_direct=False)\n",
        "def calculator(operator: operator_type, a: float, b: float) -> float:\n",
        "    \"\"\"A simple calculator tool that can add, multiply, substract, or divide two numbers.\"\"\"\n",
        "    if operator == \"add\":\n",
        "        return a + b\n",
        "    elif operator == \"multiply\":\n",
        "        return a * b\n",
        "    elif operator == \"substraction\":\n",
        "        return a - b\n",
        "    elif operator == \"division\":\n",
        "        return a / b\n",
        "    else:\n",
        "        raise ToolException(\"Invalid operator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lG6wXVH2-c2B",
        "outputId": "2b9fbc39-acd3-4c7a-943c-f4ffb71e0cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875137091,
          "user_tz": -330,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'calculator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c0e5df6ee20d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_direct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'calculator' is not defined"
          ]
        }
      ],
      "source": [
        "print(calculator.name)\n",
        "print(calculator.description)\n",
        "print(calculator.return_direct)\n",
        "print(calculator.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "n7tqPe0E-c2G",
        "outputId": "fc34d84e-87e0-4c3b-d262-5c265450921d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875141388,
          "user_tz": -330,
          "elapsed": 716,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'calculator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-d99744ec767b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"operator\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'calculator' is not defined"
          ]
        }
      ],
      "source": [
        "calculator.run({\"operator\": \"add\", \"a\": 2, \"b\": 3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHLPGOWy-c2G"
      },
      "source": [
        "### Building A Tool Calling Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0VkVCCQj-c2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1744875145379,
          "user_tz": -330,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3d9608ca-1cf3-41a8-e279-9ff482d0f8d3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'calculator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-da3cde4dd40e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'calculator' is not defined"
          ]
        }
      ],
      "source": [
        "tools = [calculator]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAOka1wB-c2G",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 22,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlG-vc3e-c2H",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvBMflvq-c2H",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZIrL_Gr-c2H",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "response = agent_executor.invoke({\n",
        "    \"input\": \"What is the product of 2 and 3?\",\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbZ92RO5-c2H"
      },
      "source": [
        "## Natural Language To Cypher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTJKmxEr-c2H",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    ChatPromptTemplate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vsC6EZb-c2H",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "neo4j_graph_vector_index = Neo4jVector.from_existing_graph(\n",
        "    embedding=OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
        "    url=os.getenv(\"NEO4J_URL\"),\n",
        "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "    index_name=\"employee\",\n",
        "    node_label=\"Employee\",\n",
        "    text_node_properties=[\n",
        "        \"address\",\n",
        "        \"city\",\n",
        "        \"title\",\n",
        "        \"email\",\n",
        "        \"postalCode\"\n",
        "        \"note\",\n",
        "        \"fistName\",\n",
        "        \"lastName\",\n",
        "        \"region\"\n",
        "    ],\n",
        "    embedding_node_property=\"embedding\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNAEHvAe-c2I",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374518,
          "user_tz": -330,
          "elapsed": 20,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "result = neo4j_graph_vector_index.similarity_search(\"Andrew\", k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVkjNr84-c2I",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4lkhczf-c2I",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "print(result[0].metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TyfJWc7-c2I",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "result = neo4j_graph_vector_index.similarity_search(\n",
        "    \"Employee detail\", filter={\"country\": \"USA\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C8hfYn1-c2J",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBio8Lhm-c2J",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 21,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "for employee in result:\n",
        "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
        "\n",
        "    print(f\"\"\"\n",
        "          First name: {clearned_page_content.get('fistName')}\n",
        "          Last name: {clearned_page_content.get('lastName')}\n",
        "          Title: {clearned_page_content.get('title')}\n",
        "          country: {employee.metadata.get('country')}\n",
        "          \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV-Ex44s-c2J",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "result = neo4j_graph_vector_index.similarity_search(\n",
        "    \"Employee detail\", filter={\"country\": {\"$ne\": 'UK'}}, k=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyrGpWWd-c2J",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RMKqOrA-c2J"
      },
      "source": [
        "$ne\n",
        "$lt\n",
        "$lte\n",
        "$gte\n",
        "$gt\n",
        "$in\n",
        "$like\n",
        "$ilke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47fQTPkb-c2K",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "for employee in result:\n",
        "    clearned_page_content = dict(line.split(\": \", 1) for line in employee.page_content.strip().split(\"\\n\"))\n",
        "\n",
        "    print(f\"\"\"\n",
        "          First name: {clearned_page_content.get('fistName')}\n",
        "          Last name: {clearned_page_content.get('lastName')}\n",
        "          Title: {clearned_page_content.get('title')}\n",
        "          country: {employee.metadata.get('country')}\n",
        "          \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYlZrVmS-c2K",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "employee_details_chat_template_str = \"\"\"\n",
        "Your job is to use the provided employee data to answer\n",
        "questions about their roles, performance, and experiences\n",
        "within the company. Use the following context to answer questions.\n",
        "Be as detailed as possible, but don't make up any information that's\n",
        "not from the context. If you don't know an answer, say you don't know.\n",
        "\n",
        "Context: {context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih-cM5KS-c2K",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374519,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=employee_details_chat_template_str\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt3WItLz-c2K",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"question\"],\n",
        "        template=\"Can you provide details on: {question}?\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IV_LlRH-c2K",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "messages = [employee_details_chat_system_prompt, human_prompt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7Vw5iPy-c2L",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "qa_prompt = ChatPromptTemplate(\n",
        "    messages=messages,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSHUlFIG-c2L",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f05IPGg-c2L",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=neo4j_graph_vector_index.as_retriever(),\n",
        "    chain_type=\"stuff\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txFj3t9x-c2L",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O175wXoC-c2L",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "response = qa_chain.invoke(\"Give me profile details of Dodsworth.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVev9UB2-c2L",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "print(response.get(\"result\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktxDNxM3-c2M",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jch7VXrz-c2M",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "graph = Neo4jGraph(\n",
        "    url=os.getenv(\"NEO4J_URL\"),\n",
        "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD-thXK1-c2M",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374520,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "graph.refresh_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-bf44Se-c2M",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "cypher_generation_template = \"\"\"\n",
        "Task:\n",
        "Generate Cypher query for a Neo4j graph database.\n",
        "\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "\n",
        "Schema:\n",
        "{schema}\n",
        "\n",
        "Note:\n",
        "Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything other than\n",
        "for you to construct a Cypher statement. Do not include any text except\n",
        "the generated Cypher statement. Make sure the direction of the relationship is\n",
        "correct in your queries. Make sure you alias both entities and relationships\n",
        "properly. Do not run any queries that would add to or delete from\n",
        "the database. Make sure to alias all statements that follow as with\n",
        "statement (e.g. WITH c as customer, o.orderID as order_id).\n",
        "If you need to divide numbers, make sure to\n",
        "filter the denominator to be non-zero.\n",
        "\n",
        "Examples:\n",
        "# Retrieve the total number of orders placed by each customer.\n",
        "MATCH (c:Customer)-[o:ORDERED_BY]->(order:Order)\n",
        "RETURN c.customerID AS customer_id, COUNT(o) AS total_orders\n",
        "# List the top 5 products with the highest unit price.\n",
        "MATCH (p:Product)\n",
        "RETURN p.productName AS product_name, p.unitPrice AS unit_price\n",
        "ORDER BY unit_price DESC\n",
        "LIMIT 5\n",
        "# Find all employees who have processed orders.\n",
        "MATCH (e:Employee)-[r:PROCESSED_BY]->(o:Order)\n",
        "RETURN e.employeeID AS employee_id, COUNT(o) AS orders_processed\n",
        "String category values:\n",
        "Use existing strings and values from the schema provided.\n",
        "\n",
        "The question is:\n",
        "{question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiYMYQH--c2N",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "cypher_generation_prompt = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=cypher_generation_template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYk8Yokg-c2N",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "qa_generation_template_str = \"\"\"\n",
        "You are an assistant that takes the results from a Neo4j Cypher query and forms a human-readable response. The query results section contains the results of a Cypher query that was generated based on a user's natural language question. The provided information is authoritative; you must never question it or use your internal knowledge to alter it. Make the answer sound like a response to the question.\n",
        "\n",
        "Query Results:\n",
        "{context}\n",
        "Question:\n",
        "{question}\n",
        "If the provided information is empty, respond by stating that you don't know the answer. Empty information is indicated by: []\n",
        "If the information is not empty, you must provide an answer using the results. If the question involves a time duration, assume the query results are in units of days unless specified otherwise.\n",
        "When names are provided in the query results, such as hospital names, be cautious of any names containing commas or other punctuation. For example, 'Jones, Brown and Murray' is a single hospital name, not multiple hospitals. Ensure that any list of names is presented clearly to avoid ambiguity and make the full names easily identifiable.\n",
        "Never state that you lack sufficient information if data is present in the query results. Always utilize the data provided.\n",
        "Helpful Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DjKoaIC-c2N",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "qa_generation_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"], template=qa_generation_template_str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzrLECBH-c2N",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    top_k=10,\n",
        "    graph=graph,\n",
        "    verbose=True,\n",
        "    validate_cypher=True,\n",
        "    qa_prompt=qa_generation_prompt,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    qa_llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
        "    cypher_llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7ENO2iA-c2N",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "question = \"What is the most expensive product?\"\n",
        "response = cypher_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoqfLoIL-c2O",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "print(response.get(\"result\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZlYzr8f-c2O",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "question = \"List the top 5 products with the highest unit price.\"\n",
        "response = cypher_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uBqRGua-c2O",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "print(response.get(\"result\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9fMvSLV-c2O",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "question = \"Give me more details on each shipper as well as how many orders they have shipped.\"\n",
        "response = cypher_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2epQNOIc-c2O",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374521,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "print(response.get(\"result\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Um8G7zl-c2P"
      },
      "source": [
        "## Agents In GraphRAG Systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni9CDsz3-c2P",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "employee_details_chat_template_str = \"\"\"\n",
        "Your job is to use the provided employee data to answer\n",
        "questions about their roles, performance, and experiences\n",
        "within the company. Use the following context to answer questions.\n",
        "Be as detailed as possible, but don't make up any information that's\n",
        "not from the context. If you don't know an answer, say you don't know.\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UFjh7w5-c2P",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "@tool(\"employee-qa-tool\", return_direct=False)\n",
        "def employee_qa_tool(query: str) -> str:\n",
        "    \"\"\"Useful for answering questions about employees who work at a company.\"\"\"\n",
        "\n",
        "    employee_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"context\"],\n",
        "            template=employee_details_chat_template_str\n",
        "        )\n",
        "    )\n",
        "\n",
        "    human_prompt = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"question\"],\n",
        "            template=\"Can you provide details on: {question}?\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    messages = [employee_details_chat_system_prompt, human_prompt]\n",
        "\n",
        "    qa_prompt = ChatPromptTemplate(\n",
        "        messages=messages,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=neo4j_graph_vector_index.as_retriever(),\n",
        "        # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
        "        chain_type=\"stuff\",\n",
        "    )\n",
        "\n",
        "    qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt\n",
        "\n",
        "    response = qa_chain.invoke(query)\n",
        "\n",
        "    return response.get(\"result\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjLsKrFD-c2P",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "employee_qa_tool.invoke(\"What is the address of Andrew?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4HaHQA0-c2Q",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "@tool(\"general-qa-tool\", return_direct=False)\n",
        "def general_qa_tool(query: str) -> str:\n",
        "    \"\"\"Useful for answering general questions about orders, order details, shipper, customers, and products.\"\"\"\n",
        "    response = cypher_chain.invoke(query)\n",
        "\n",
        "    return response.get(\"result\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SJ-8blR-c2Q",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "general_qa_tool.invoke(\"What is the most expensive product?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJ6eJx6-c2Q"
      },
      "source": [
        "### Creating Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEsg8__G-c2Q",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import (\n",
        "    AgentExecutor,\n",
        "    create_openai_tools_agent\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9PqxkRQ-c2Q",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUpRCK7P-c2R",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent_prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZFFWI89-c2R",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "tools = [employee_qa_tool, general_qa_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSfQ0aJ5-c2R",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MRJH2z7-c2R",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374522,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm, tools, agent_prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foxAPPCv-c2R",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374523,
          "user_tz": -330,
          "elapsed": 19,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"What is the most expensive product?\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfSWidM_-c2R",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374523,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"What is the address of Dodsworth?\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Dt6l9c-c2S",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1744874374523,
          "user_tz": -330,
          "elapsed": 18,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "name": "chatbot.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}